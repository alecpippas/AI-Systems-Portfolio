{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 - Object Detection\n",
    "By: Alec Pippas (awp251)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Object Detection of Car in Short Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video_to_frames(video_path, frames_folder):\n",
    "    \"\"\"\n",
    "    Splits a video into frames and saves them into the specified folder.\n",
    "    \"\"\"\n",
    "    os.makedirs(frames_folder, exist_ok=True)\n",
    "    captured_vid = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        #reads one frame per iteration, .read() returns a tuple (ret, frame)\n",
    "        # ret: boolean indicating if frame was successfully read\n",
    "        # frame: frame image stored as NumPy array\n",
    "        ret, frame = captured_vid.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imwrite(os.path.join(frames_folder, f'frame_{frame_count:06d}.jpg'), frame) # save current frame withi the frames_folder\n",
    "        frame_count += 1\n",
    "\n",
    "    #free up resources (file handles, memory) associated with the cv2.VideoCaptuer object\n",
    "    captured_vid.release() \n",
    "    return frame_count\n",
    "\n",
    "\n",
    "\n",
    "def detect_and_annotate(frames_folder, processed_folder, model, total_frames, csv_file=\"detections.csv\"):\n",
    "    \"\"\"\n",
    "    Performs object detection on each frame using a YOLO model,\n",
    "    draws bounding boxes (for cars) with centroids, saves new frames,\n",
    "    and logs the car centroids to a CSV.\n",
    "    \"\"\"\n",
    "    os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "    # Open CSV for writing all detections (frame_idx, conf, cx, cy)\n",
    "    with open(csv_file, mode=\"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        # Write a header row (customize as you like)\n",
    "        writer.writerow([\"frame_idx\", \"conf\", \"cx\", \"cy\"])\n",
    "\n",
    "        for i in range(total_frames):\n",
    "            frame_path = os.path.join(frames_folder, f'frame_{i:06d}.jpg')\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                continue\n",
    "\n",
    "            # Run object detection\n",
    "            results = model(frame)  # Optionally: model(frame, conf=0.6)\n",
    "\n",
    "            # Draw bounding boxes and centroids\n",
    "            for r in results:\n",
    "                for box in r.boxes:\n",
    "                    class_idx = int(box.cls[0])  # predicted class index\n",
    "                    label = r.names[class_idx]   # class label (e.g., \"car\")\n",
    "                    if label == \"car\":\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                        conf = float(box.conf[0])\n",
    "\n",
    "                        # Draw bounding box\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "                        # Class label + confidence\n",
    "                        text = f\"{label} {conf:.2f}\"\n",
    "                        cv2.putText(frame, text, (x1, y1 - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                        # Compute and draw centroid\n",
    "                        cx = (x1 + x2) // 2\n",
    "                        cy = (y1 + y2) // 2\n",
    "                        cv2.circle(frame, (cx, cy), 5, (0, 255, 0), -1)\n",
    "\n",
    "                        # Write one row per detection to CSV\n",
    "                        writer.writerow([i, f\"{conf:.2f}\", cx, cy])\n",
    "\n",
    "            # Save the annotated frame\n",
    "            cv2.imwrite(os.path.join(processed_folder, f'frame_{i:06d}.jpg'), frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_video_from_frames(processed_folder, output_video, total_frames, fps=30):\n",
    "    \"\"\"\n",
    "    Rebuilds a video from processed frames.\n",
    "    \"\"\"\n",
    "    # Read the first frame to get size info\n",
    "    first_frame_path = os.path.join(processed_folder, 'frame_000000.jpg')\n",
    "    first_frame = cv2.imread(first_frame_path)\n",
    "    \n",
    "    #raise execption if the frame was not read (may indicate the frame was not extracted/processed correctly)\n",
    "    if first_frame is None:\n",
    "        raise FileNotFoundError(f\"Could not read the file: {first_frame_path}\")\n",
    "\n",
    "    height, width, _ = first_frame.shape\n",
    "\n",
    "    # Create VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  \n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "    # Write each processed frame to the new video\n",
    "    for i in range(total_frames):\n",
    "        processed_frame_path = os.path.join(processed_folder, f'frame_{i:06d}.jpg')\n",
    "        processed_frame = cv2.imread(processed_frame_path)\n",
    "        if processed_frame is not None:\n",
    "            out.write(processed_frame)\n",
    "\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 bus, 44.1ms\n",
      "Speed: 2.3ms preprocess, 44.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 29.7ms\n",
      "Speed: 3.3ms preprocess, 29.7ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 31.3ms\n",
      "Speed: 1.9ms preprocess, 31.3ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 30.1ms\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 8.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 23.5ms\n",
      "Speed: 2.7ms preprocess, 23.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 20.5ms\n",
      "Speed: 1.4ms preprocess, 20.5ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 21.1ms\n",
      "Speed: 1.5ms preprocess, 21.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 22.1ms\n",
      "Speed: 1.7ms preprocess, 22.1ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 19.7ms\n",
      "Speed: 1.7ms preprocess, 19.7ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 17.7ms\n",
      "Speed: 1.9ms preprocess, 17.7ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 15.1ms\n",
      "Speed: 2.3ms preprocess, 15.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 15.6ms\n",
      "Speed: 2.1ms preprocess, 15.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 15.2ms\n",
      "Speed: 1.6ms preprocess, 15.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 15.7ms\n",
      "Speed: 1.8ms preprocess, 15.7ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 19.0ms\n",
      "Speed: 1.5ms preprocess, 19.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 13.2ms\n",
      "Speed: 1.7ms preprocess, 13.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 20.4ms\n",
      "Speed: 1.4ms preprocess, 20.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 train, 17.5ms\n",
      "Speed: 1.4ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 train, 19.5ms\n",
      "Speed: 1.8ms preprocess, 19.5ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 16.4ms\n",
      "Speed: 1.7ms preprocess, 16.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 18.3ms\n",
      "Speed: 2.1ms preprocess, 18.3ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 17.1ms\n",
      "Speed: 2.4ms preprocess, 17.1ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 12.9ms\n",
      "Speed: 1.3ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.2ms\n",
      "Speed: 1.7ms preprocess, 14.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 12.9ms\n",
      "Speed: 1.4ms preprocess, 12.9ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 16.2ms\n",
      "Speed: 1.7ms preprocess, 16.2ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 14.7ms\n",
      "Speed: 1.7ms preprocess, 14.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 train, 13.6ms\n",
      "Speed: 2.1ms preprocess, 13.6ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 27.7ms\n",
      "Speed: 2.2ms preprocess, 27.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 17.1ms\n",
      "Speed: 1.6ms preprocess, 17.1ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 train, 17.6ms\n",
      "Speed: 2.1ms preprocess, 17.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 12.5ms\n",
      "Speed: 2.6ms preprocess, 12.5ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 15.8ms\n",
      "Speed: 2.4ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 13.6ms\n",
      "Speed: 2.7ms preprocess, 13.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 15.6ms\n",
      "Speed: 1.4ms preprocess, 15.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 14.3ms\n",
      "Speed: 1.6ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 14.2ms\n",
      "Speed: 1.5ms preprocess, 14.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 13.3ms\n",
      "Speed: 2.1ms preprocess, 13.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 16.9ms\n",
      "Speed: 2.7ms preprocess, 16.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 train, 1 truck, 13.9ms\n",
      "Speed: 1.6ms preprocess, 13.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 train, 1 truck, 13.5ms\n",
      "Speed: 1.6ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 14.0ms\n",
      "Speed: 1.6ms preprocess, 14.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 16.1ms\n",
      "Speed: 1.6ms preprocess, 16.1ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 17.3ms\n",
      "Speed: 2.3ms preprocess, 17.3ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 14.0ms\n",
      "Speed: 3.1ms preprocess, 14.0ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 19.0ms\n",
      "Speed: 2.1ms preprocess, 19.0ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 15.0ms\n",
      "Speed: 1.7ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 17.9ms\n",
      "Speed: 1.5ms preprocess, 17.9ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 14.6ms\n",
      "Speed: 1.5ms preprocess, 14.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.7ms\n",
      "Speed: 1.9ms preprocess, 13.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 14.2ms\n",
      "Speed: 1.5ms preprocess, 14.2ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 23.1ms\n",
      "Speed: 1.7ms preprocess, 23.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 22.7ms\n",
      "Speed: 2.9ms preprocess, 22.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.5ms\n",
      "Speed: 2.3ms preprocess, 12.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 14.6ms\n",
      "Speed: 1.6ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 12.7ms\n",
      "Speed: 1.7ms preprocess, 12.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 15.7ms\n",
      "Speed: 1.7ms preprocess, 15.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 12.3ms\n",
      "Speed: 1.8ms preprocess, 12.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 14.0ms\n",
      "Speed: 2.4ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 12.4ms\n",
      "Speed: 1.6ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 13.5ms\n",
      "Speed: 1.8ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 21.2ms\n",
      "Speed: 1.8ms preprocess, 21.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 22.6ms\n",
      "Speed: 7.1ms preprocess, 22.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 17.3ms\n",
      "Speed: 2.7ms preprocess, 17.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.8ms\n",
      "Speed: 1.8ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 19.7ms\n",
      "Speed: 2.0ms preprocess, 19.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 19.6ms\n",
      "Speed: 2.0ms preprocess, 19.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.6ms\n",
      "Speed: 1.4ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.2ms\n",
      "Speed: 1.6ms preprocess, 13.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 12.2ms\n",
      "Speed: 3.0ms preprocess, 12.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 14.2ms\n",
      "Speed: 1.9ms preprocess, 14.2ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 12.8ms\n",
      "Speed: 1.5ms preprocess, 12.8ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 14.6ms\n",
      "Speed: 1.4ms preprocess, 14.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 19.1ms\n",
      "Speed: 1.9ms preprocess, 19.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 12.1ms\n",
      "Speed: 1.7ms preprocess, 12.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.7ms\n",
      "Speed: 1.9ms preprocess, 15.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.2ms\n",
      "Speed: 2.1ms preprocess, 13.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.4ms\n",
      "Speed: 1.6ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 17.6ms\n",
      "Speed: 2.1ms preprocess, 17.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.3ms\n",
      "Speed: 2.7ms preprocess, 14.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 train, 14.3ms\n",
      "Speed: 1.9ms preprocess, 14.3ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 17.6ms\n",
      "Speed: 2.2ms preprocess, 17.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.5ms\n",
      "Speed: 2.7ms preprocess, 14.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 16.8ms\n",
      "Speed: 2.5ms preprocess, 16.8ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 21.2ms\n",
      "Speed: 1.7ms preprocess, 21.2ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 18.1ms\n",
      "Speed: 2.1ms preprocess, 18.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.2ms\n",
      "Speed: 1.4ms preprocess, 15.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 19.4ms\n",
      "Speed: 2.0ms preprocess, 19.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 18.8ms\n",
      "Speed: 2.1ms preprocess, 18.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.2ms\n",
      "Speed: 1.7ms preprocess, 15.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.2ms\n",
      "Speed: 1.5ms preprocess, 14.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 14.3ms\n",
      "Speed: 1.8ms preprocess, 14.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 18.7ms\n",
      "Speed: 2.0ms preprocess, 18.7ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 19.6ms\n",
      "Speed: 1.9ms preprocess, 19.6ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.1ms\n",
      "Speed: 1.8ms preprocess, 14.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.2ms\n",
      "Speed: 1.9ms preprocess, 14.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 14.8ms\n",
      "Speed: 1.4ms preprocess, 14.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 12.2ms\n",
      "Speed: 1.9ms preprocess, 12.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 train, 13.5ms\n",
      "Speed: 1.6ms preprocess, 13.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 13.4ms\n",
      "Speed: 1.7ms preprocess, 13.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 13.7ms\n",
      "Speed: 2.2ms preprocess, 13.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 12.6ms\n",
      "Speed: 1.5ms preprocess, 12.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.5ms\n",
      "Speed: 2.9ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.5ms\n",
      "Speed: 1.7ms preprocess, 12.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.7ms\n",
      "Speed: 1.8ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.7ms\n",
      "Speed: 2.4ms preprocess, 15.7ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.7ms\n",
      "Speed: 1.7ms preprocess, 13.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.5ms\n",
      "Speed: 1.8ms preprocess, 13.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.7ms\n",
      "Speed: 1.9ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.1ms\n",
      "Speed: 1.7ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.1ms\n",
      "Speed: 2.5ms preprocess, 12.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.5ms\n",
      "Speed: 1.4ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.8ms\n",
      "Speed: 1.7ms preprocess, 14.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 17.5ms\n",
      "Speed: 1.8ms preprocess, 17.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 17.6ms\n",
      "Speed: 1.5ms preprocess, 17.6ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.1ms\n",
      "Speed: 1.8ms preprocess, 14.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 13.7ms\n",
      "Speed: 3.1ms preprocess, 13.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 15.8ms\n",
      "Speed: 1.9ms preprocess, 15.8ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 12.4ms\n",
      "Speed: 1.8ms preprocess, 12.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 21.4ms\n",
      "Speed: 1.8ms preprocess, 21.4ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 16.8ms\n",
      "Speed: 1.9ms preprocess, 16.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 12.3ms\n",
      "Speed: 2.5ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.9ms\n",
      "Speed: 2.1ms preprocess, 14.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 12.4ms\n",
      "Speed: 1.8ms preprocess, 12.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 1 truck, 15.7ms\n",
      "Speed: 1.9ms preprocess, 15.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 11.2ms\n",
      "Speed: 1.7ms preprocess, 11.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 15.3ms\n",
      "Speed: 1.9ms preprocess, 15.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 13.6ms\n",
      "Speed: 2.1ms preprocess, 13.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 16.1ms\n",
      "Speed: 2.1ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 1 truck, 19.3ms\n",
      "Speed: 1.9ms preprocess, 19.3ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 1 truck, 13.8ms\n",
      "Speed: 1.6ms preprocess, 13.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 16.4ms\n",
      "Speed: 2.4ms preprocess, 16.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 20.9ms\n",
      "Speed: 2.2ms preprocess, 20.9ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 19.1ms\n",
      "Speed: 1.9ms preprocess, 19.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 1 truck, 13.5ms\n",
      "Speed: 1.6ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 21.8ms\n",
      "Speed: 2.3ms preprocess, 21.8ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 20.5ms\n",
      "Speed: 1.8ms preprocess, 20.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 13.8ms\n",
      "Speed: 2.6ms preprocess, 13.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.9ms\n",
      "Speed: 1.9ms preprocess, 14.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 13.3ms\n",
      "Speed: 2.8ms preprocess, 13.3ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 13.7ms\n",
      "Speed: 1.9ms preprocess, 13.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 17.0ms\n",
      "Speed: 2.1ms preprocess, 17.0ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 1 truck, 14.1ms\n",
      "Speed: 1.4ms preprocess, 14.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 15.6ms\n",
      "Speed: 2.2ms preprocess, 15.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 train, 1 truck, 13.8ms\n",
      "Speed: 2.0ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.5ms\n",
      "Speed: 1.7ms preprocess, 13.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 14.5ms\n",
      "Speed: 1.6ms preprocess, 14.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 15.9ms\n",
      "Speed: 1.7ms preprocess, 15.9ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 24.2ms\n",
      "Speed: 1.7ms preprocess, 24.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 15.8ms\n",
      "Speed: 1.9ms preprocess, 15.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 20.1ms\n",
      "Speed: 1.7ms preprocess, 20.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 16.0ms\n",
      "Speed: 1.7ms preprocess, 16.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.8ms\n",
      "Speed: 1.8ms preprocess, 13.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 12.6ms\n",
      "Speed: 1.7ms preprocess, 12.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 14.5ms\n",
      "Speed: 1.9ms preprocess, 14.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 14.1ms\n",
      "Speed: 1.6ms preprocess, 14.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 12.2ms\n",
      "Speed: 1.6ms preprocess, 12.2ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 14.6ms\n",
      "Speed: 1.3ms preprocess, 14.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 14.2ms\n",
      "Speed: 1.9ms preprocess, 14.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.2ms\n",
      "Speed: 1.6ms preprocess, 14.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 12.1ms\n",
      "Speed: 1.5ms preprocess, 12.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 17.2ms\n",
      "Speed: 1.7ms preprocess, 17.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.8ms\n",
      "Speed: 1.4ms preprocess, 15.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.8ms\n",
      "Speed: 1.6ms preprocess, 12.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.0ms\n",
      "Speed: 1.7ms preprocess, 12.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.4ms\n",
      "Speed: 2.2ms preprocess, 12.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.5ms\n",
      "Speed: 1.7ms preprocess, 13.5ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.2ms\n",
      "Speed: 3.1ms preprocess, 12.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.2ms\n",
      "Speed: 1.7ms preprocess, 11.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.6ms\n",
      "Speed: 1.8ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.7ms\n",
      "Speed: 1.8ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.5ms\n",
      "Speed: 1.3ms preprocess, 15.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.1ms\n",
      "Speed: 1.8ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 13.5ms\n",
      "Speed: 1.3ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.5ms\n",
      "Speed: 1.5ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.9ms\n",
      "Speed: 2.7ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 12.6ms\n",
      "Speed: 1.4ms preprocess, 12.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.7ms\n",
      "Speed: 1.7ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 15.7ms\n",
      "Speed: 1.7ms preprocess, 15.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 13.3ms\n",
      "Speed: 1.6ms preprocess, 13.3ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.2ms\n",
      "Speed: 2.0ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.6ms\n",
      "Speed: 2.2ms preprocess, 12.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.5ms\n",
      "Speed: 1.4ms preprocess, 14.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.3ms\n",
      "Speed: 1.7ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 15.6ms\n",
      "Speed: 2.6ms preprocess, 15.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 10.1ms\n",
      "Speed: 1.7ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 13.5ms\n",
      "Speed: 1.4ms preprocess, 13.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 12.9ms\n",
      "Speed: 1.6ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.9ms\n",
      "Speed: 1.5ms preprocess, 11.9ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.4ms\n",
      "Speed: 1.4ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.1ms\n",
      "Speed: 1.4ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.3ms\n",
      "Speed: 1.6ms preprocess, 13.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.3ms\n",
      "Speed: 1.2ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.3ms\n",
      "Speed: 1.5ms preprocess, 13.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.2ms\n",
      "Speed: 1.7ms preprocess, 14.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 10.2ms\n",
      "Speed: 1.3ms preprocess, 10.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.8ms\n",
      "Speed: 2.5ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 16.8ms\n",
      "Speed: 1.6ms preprocess, 16.8ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.6ms\n",
      "Speed: 1.4ms preprocess, 14.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 23.6ms\n",
      "Speed: 1.7ms preprocess, 23.6ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 22.0ms\n",
      "Speed: 1.7ms preprocess, 22.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 1 truck, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.8ms\n",
      "Speed: 1.5ms preprocess, 13.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.4ms\n",
      "Speed: 1.3ms preprocess, 13.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.0ms\n",
      "Speed: 1.6ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.2ms\n",
      "Speed: 2.8ms preprocess, 12.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.0ms\n",
      "Speed: 1.7ms preprocess, 14.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 20.5ms\n",
      "Speed: 3.8ms preprocess, 20.5ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 9.9ms\n",
      "Speed: 2.1ms preprocess, 9.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.8ms\n",
      "Speed: 1.6ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.8ms\n",
      "Speed: 1.8ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 10.2ms\n",
      "Speed: 1.4ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 17.3ms\n",
      "Speed: 1.1ms preprocess, 17.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.5ms\n",
      "Speed: 1.6ms preprocess, 15.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.3ms\n",
      "Speed: 1.3ms preprocess, 15.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 10.0ms\n",
      "Speed: 1.7ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.2ms\n",
      "Speed: 1.4ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.8ms\n",
      "Speed: 3.8ms preprocess, 12.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.2ms\n",
      "Speed: 1.6ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.3ms\n",
      "Speed: 1.8ms preprocess, 14.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.9ms\n",
      "Speed: 1.2ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.0ms\n",
      "Speed: 2.2ms preprocess, 13.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 10.3ms\n",
      "Speed: 1.4ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.9ms\n",
      "Speed: 1.2ms preprocess, 11.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.9ms\n",
      "Speed: 1.4ms preprocess, 14.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.6ms\n",
      "Speed: 3.5ms preprocess, 13.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.5ms\n",
      "Speed: 1.4ms preprocess, 13.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.8ms\n",
      "Speed: 2.1ms preprocess, 15.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 19.4ms\n",
      "Speed: 2.4ms preprocess, 19.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.9ms\n",
      "Speed: 2.2ms preprocess, 13.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.2ms\n",
      "Speed: 1.7ms preprocess, 14.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.0ms\n",
      "Speed: 1.4ms preprocess, 15.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.2ms\n",
      "Speed: 1.8ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.9ms\n",
      "Speed: 2.3ms preprocess, 14.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.1ms\n",
      "Speed: 1.5ms preprocess, 13.1ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.3ms\n",
      "Speed: 1.9ms preprocess, 14.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.5ms\n",
      "Speed: 1.7ms preprocess, 13.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.8ms\n",
      "Speed: 1.3ms preprocess, 12.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.5ms\n",
      "Speed: 1.9ms preprocess, 13.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.0ms\n",
      "Speed: 1.5ms preprocess, 13.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.4ms\n",
      "Speed: 1.9ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 13.1ms\n",
      "Speed: 1.7ms preprocess, 13.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.6ms\n",
      "Speed: 1.6ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.5ms\n",
      "Speed: 1.6ms preprocess, 11.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.0ms\n",
      "Speed: 1.6ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.9ms\n",
      "Speed: 2.0ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.8ms\n",
      "Speed: 1.8ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.8ms\n",
      "Speed: 1.6ms preprocess, 14.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.5ms\n",
      "Speed: 1.7ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 12.7ms\n",
      "Speed: 1.6ms preprocess, 12.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.4ms\n",
      "Speed: 1.7ms preprocess, 13.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 18.7ms\n",
      "Speed: 4.7ms preprocess, 18.7ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 20.1ms\n",
      "Speed: 3.5ms preprocess, 20.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 16.4ms\n",
      "Speed: 2.5ms preprocess, 16.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 17.5ms\n",
      "Speed: 2.6ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 13.9ms\n",
      "Speed: 2.5ms preprocess, 13.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.9ms\n",
      "Speed: 2.4ms preprocess, 13.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.4ms\n",
      "Speed: 2.1ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.6ms\n",
      "Speed: 1.6ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 14.6ms\n",
      "Speed: 2.2ms preprocess, 14.6ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 train, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.3ms\n",
      "Speed: 1.6ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.2ms\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.8ms\n",
      "Speed: 1.7ms preprocess, 14.8ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.1ms\n",
      "Speed: 1.6ms preprocess, 15.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 train, 13.4ms\n",
      "Speed: 2.2ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 17.6ms\n",
      "Speed: 1.6ms preprocess, 17.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.3ms\n",
      "Speed: 1.7ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.6ms\n",
      "Speed: 1.7ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.0ms\n",
      "Speed: 1.7ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.6ms\n",
      "Speed: 1.6ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.1ms\n",
      "Speed: 1.7ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.2ms\n",
      "Speed: 1.5ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.6ms\n",
      "Speed: 1.6ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.8ms\n",
      "Speed: 2.4ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.1ms\n",
      "Speed: 1.8ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 14.3ms\n",
      "Speed: 1.4ms preprocess, 14.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.9ms\n",
      "Speed: 1.8ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 12.0ms\n",
      "Speed: 1.6ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.5ms\n",
      "Speed: 2.4ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 12.1ms\n",
      "Speed: 1.6ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.0ms\n",
      "Speed: 1.7ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.5ms\n",
      "Speed: 2.3ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.8ms\n",
      "Speed: 1.6ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.7ms\n",
      "Speed: 1.9ms preprocess, 13.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 14.1ms\n",
      "Speed: 1.7ms preprocess, 14.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.3ms\n",
      "Speed: 1.5ms preprocess, 13.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.2ms\n",
      "Speed: 2.1ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.3ms\n",
      "Speed: 1.6ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.5ms\n",
      "Speed: 1.9ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.3ms\n",
      "Speed: 2.3ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.4ms\n",
      "Speed: 1.9ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.2ms\n",
      "Speed: 1.8ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.3ms\n",
      "Speed: 1.6ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 10.8ms\n",
      "Speed: 1.9ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 12.6ms\n",
      "Speed: 1.5ms preprocess, 12.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 14.9ms\n",
      "Speed: 1.5ms preprocess, 14.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 10.8ms\n",
      "Speed: 1.6ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 14.9ms\n",
      "Speed: 2.1ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 13.0ms\n",
      "Speed: 2.9ms preprocess, 13.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.0ms\n",
      "Speed: 1.6ms preprocess, 14.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 14.3ms\n",
      "Speed: 1.6ms preprocess, 14.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 12.3ms\n",
      "Speed: 1.9ms preprocess, 12.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 12.7ms\n",
      "Speed: 2.0ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.0ms\n",
      "Speed: 2.3ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.0ms\n",
      "Speed: 1.7ms preprocess, 11.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.4ms\n",
      "Speed: 2.2ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.5ms\n",
      "Speed: 1.9ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.3ms\n",
      "Speed: 1.7ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 18.4ms\n",
      "Speed: 2.1ms preprocess, 18.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 20.0ms\n",
      "Speed: 1.7ms preprocess, 20.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.8ms\n",
      "Speed: 2.1ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 19.8ms\n",
      "Speed: 2.0ms preprocess, 19.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.5ms\n",
      "Speed: 1.5ms preprocess, 14.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 18.6ms\n",
      "Speed: 1.6ms preprocess, 18.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 25.0ms\n",
      "Speed: 1.5ms preprocess, 25.0ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.3ms\n",
      "Speed: 1.7ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.2ms\n",
      "Speed: 1.3ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.0ms\n",
      "Speed: 1.2ms preprocess, 15.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.6ms\n",
      "Speed: 1.8ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.0ms\n",
      "Speed: 1.4ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.6ms\n",
      "Speed: 1.7ms preprocess, 13.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.8ms\n",
      "Speed: 2.2ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.5ms\n",
      "Speed: 1.7ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 13.1ms\n",
      "Speed: 1.5ms preprocess, 13.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.9ms\n",
      "Speed: 1.8ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.3ms\n",
      "Speed: 1.7ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.7ms\n",
      "Speed: 1.4ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.0ms\n",
      "Speed: 2.4ms preprocess, 14.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.4ms\n",
      "Speed: 1.6ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.3ms\n",
      "Speed: 1.9ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.0ms\n",
      "Speed: 1.4ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.8ms\n",
      "Speed: 1.5ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.6ms\n",
      "Speed: 1.6ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.0ms\n",
      "Speed: 1.6ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.6ms\n",
      "Speed: 1.3ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.2ms\n",
      "Speed: 1.9ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.7ms\n",
      "Speed: 1.5ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.9ms\n",
      "Speed: 1.6ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.9ms\n",
      "Speed: 1.6ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.9ms\n",
      "Speed: 1.6ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.5ms\n",
      "Speed: 1.7ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.3ms\n",
      "Speed: 1.8ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.5ms\n",
      "Speed: 2.8ms preprocess, 14.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.5ms\n",
      "Speed: 3.3ms preprocess, 16.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.7ms\n",
      "Speed: 1.4ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.5ms\n",
      "Speed: 1.8ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 22.9ms\n",
      "Speed: 4.4ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 19.7ms\n",
      "Speed: 2.4ms preprocess, 19.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.6ms\n",
      "Speed: 1.4ms preprocess, 13.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.9ms\n",
      "Speed: 2.2ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.7ms\n",
      "Speed: 1.7ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.4ms\n",
      "Speed: 1.7ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.1ms\n",
      "Speed: 1.4ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.7ms\n",
      "Speed: 1.6ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.9ms\n",
      "Speed: 1.7ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.7ms\n",
      "Speed: 1.6ms preprocess, 14.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.0ms\n",
      "Speed: 1.6ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.3ms\n",
      "Speed: 2.6ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.4ms\n",
      "Speed: 1.4ms preprocess, 13.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.4ms\n",
      "Speed: 1.6ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.2ms\n",
      "Speed: 1.7ms preprocess, 15.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.0ms\n",
      "Speed: 1.8ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.0ms\n",
      "Speed: 2.2ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.9ms\n",
      "Speed: 2.4ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.8ms\n",
      "Speed: 1.6ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.0ms\n",
      "Speed: 1.7ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.7ms\n",
      "Speed: 1.6ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.1ms\n",
      "Speed: 3.0ms preprocess, 16.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.9ms\n",
      "Speed: 1.3ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Object Detection with bounding boxes now complete. Annotated video has been savet to: output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "#1) Split the video into frames\n",
    "video_path = \"Assignment_3_video_ActiveTrack\"\n",
    "frames_folder = \"extracted_frames\"\n",
    "total_frames = split_video_to_frames(video_path, frames_folder)\n",
    "\n",
    "#2) Load a YOLO model (YOLOv8s pretrained on COCO)\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "#3. Detect and annotate frames with bounding box + centroid for \"car\" objects\n",
    "processed_folder = \"processed_frames\"\n",
    "detect_and_annotate(frames_folder, processed_folder, model, total_frames)\n",
    "                    \n",
    "#4. Rebuild the annotated frames into a new video\n",
    "output_video = \"output_video.mp4\"\n",
    "rebuild_video_from_frames(processed_folder, output_video, total_frames, fps=30)\n",
    "print(f\"Object Detection with bounding boxes now complete. Annotated video has been savet to: {output_video}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Kalman Filters with filterpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from filterpy.common import Q_discrete_white_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_kalman_filter(dt=1.0, process_var=1.0, measurement_var=5.0):\n",
    "    \"\"\"\n",
    "    Initializes a 2D Kalman Filter tracking (x, y, vx, vy).\n",
    "    dt: time step between frames (assume 1 frame per 'unit time')\n",
    "    process_var: process (model) variance\n",
    "    measurement_var: measurement variance\n",
    "    \"\"\"\n",
    "    kf = KalmanFilter(dim_x=4, dim_z=2)\n",
    "    \n",
    "    # State vector: [x, y, vx, vy]\n",
    "    # We'll initialize this dynamically once we get the first measurement.\n",
    "    kf.x = np.array([0, 0, 0, 0], dtype=float)\n",
    "    \n",
    "    # State transition matrix (F)\n",
    "    # [x]   [1  0  dt  0]\n",
    "    # [y] = [0  1  0   dt]\n",
    "    # [vx]  [0  0  1   0 ]\n",
    "    # [vy]  [0  0  0   1 ]\n",
    "    kf.F = np.array([[1, 0, dt, 0],\n",
    "                     [0, 1, 0, dt],\n",
    "                     [0, 0, 1, 0 ],\n",
    "                     [0, 0, 0, 1 ]], dtype=float)\n",
    "    \n",
    "    # Measurement function (H)\n",
    "    # We measure (x, y) only, so we map [x, y, vx, vy] -> [x, y].\n",
    "    kf.H = np.array([[1, 0, 0, 0],\n",
    "                     [0, 1, 0, 0]], dtype=float)\n",
    "    \n",
    "    # Covariance matrix (P)\n",
    "    # Initialize with some large uncertainty for velocities.\n",
    "    kf.P = np.eye(4) * 500.\n",
    "    \n",
    "    # R: measurement noise covariance\n",
    "    # We assume measurement noise is the same for x and y\n",
    "    kf.R = np.eye(2) * measurement_var\n",
    "    \n",
    "    # Q: process noise covariance\n",
    "    # We'll generate some basic process noise for the velocity components\n",
    "    q = Q_discrete_white_noise(dim=2, dt=dt, var=process_var)\n",
    "    # Q_discrete_white_noise generates a 2x2 matrix for the subspace (vx, vy).\n",
    "    # We need to embed it in a 4x4 for the full state.\n",
    "    kf.Q = np.block([\n",
    "        [np.zeros((2,2)),           np.zeros((2,2))],\n",
    "        [np.zeros((2,2)),           q              ]\n",
    "    ])\n",
    "    \n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measurement_for_frame(bboxes, frame_idx):\n",
    "    \"\"\"\n",
    "    Returns the (x, y) measurement for the given frame_idx\n",
    "    or None if no measurement is available.\n",
    "    \"\"\"\n",
    "    for (f_idx, x, y) in bboxes:\n",
    "        if f_idx == frame_idx:\n",
    "            return (x, y)\n",
    "    return None\n",
    "\n",
    "def rebuild_video(folder_path, output_video, total_frames, fps=30):\n",
    "    \"\"\"\n",
    "    Rebuilds a video from frames in folder_path,\n",
    "    saving it to output_video.\n",
    "    \"\"\"\n",
    "    first_frame_path = os.path.join(folder_path, \"frame_000000.jpg\")\n",
    "    first_frame = cv2.imread(first_frame_path)\n",
    "    if first_frame is None:\n",
    "        raise RuntimeError(\"No frames found to build video.\")\n",
    "    \n",
    "    height, width, _ = first_frame.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "    for i in range(total_frames):\n",
    "        frame_path = os.path.join(folder_path, f\"frame_{i:06d}.jpg\")\n",
    "        frame = cv2.imread(frame_path)\n",
    "        if frame is None:\n",
    "            continue\n",
    "        out.write(frame)\n",
    "    \n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bounding_box_centers(csv_file=\"detections.csv\"):\n",
    "    \"\"\"\n",
    "    Loads bounding box centers from a CSV file.\n",
    "    It Expects columns: frame_idx, x_center, y_center.\n",
    "    \n",
    "    Returns:\n",
    "        A list of tuples (frame_idx, x_center, y_center).\n",
    "    \"\"\"\n",
    "    bounding_boxes = []\n",
    "\n",
    "    with open(csv_file, 'r', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip header row if exist\n",
    "        for row in reader:\n",
    "            frame_idx = int(row[0])\n",
    "            x_center = float(row[2]) #centroid x_coordinate\n",
    "            y_center = float(row[3])  #centroid y_coordinate\n",
    "            bounding_boxes.append((frame_idx, x_center, y_center))\n",
    "    return bounding_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # --- 1. Prepare input paths ---\n",
    "    # The folder with frames from the YOLO detection step\n",
    "    processed_folder = \"processed_frames\"  # or \"extracted_frames\"\n",
    "    # specify new folder to store frames with the Kalman-filtered track\n",
    "    kalman_folder = \"kalman_filtered_frames\"\n",
    "    os.makedirs(kalman_folder, exist_ok=True)\n",
    "    \n",
    "    # The bounding box data for each frame (x_center, y_center).  \n",
    "    # Ex. bounding_boxes = [(0, 100, 200), (1, 101, 202), ...]\n",
    "    bounding_boxes = load_bounding_box_centers(\"detections.csv\")\n",
    "    \n",
    "    # Get Number of frames\n",
    "    total_frames = len(os.listdir(processed_folder))\n",
    "    \n",
    "    # 2) Initialize Kalman Filter\n",
    "    kf = initialize_kalman_filter(dt=1.0, process_var=1.0, measurement_var=5.0)\n",
    "    initialized = False\n",
    "    \n",
    "    # We'll store the innovation norm to analyze filter performance\n",
    "    innovation_norms = []\n",
    "    \n",
    "    # --- 3. Tracking Loop ---\n",
    "    for i in range(total_frames):\n",
    "        # Attempt to read bounding box center for frame i\n",
    "        # If no detection is found for this frame, measurement = None\n",
    "        measurement = get_measurement_for_frame(bounding_boxes, i)  # returns (x, y) or None\n",
    "        \n",
    "        # Kalman Filter: PREDICT step\n",
    "        kf.predict()\n",
    "        \n",
    "        # If we do not have an initial measurement yet, we skip update\n",
    "        # and just wait until we get a real measurement to initialize properly\n",
    "        if not initialized and measurement is not None:\n",
    "            # Initialize the filter state [x, y, vx, vy]\n",
    "            kf.x[0] = measurement[0]\n",
    "            kf.x[1] = measurement[1]\n",
    "            kf.x[2] = 0.0\n",
    "            kf.x[3] = 0.0 \n",
    "            # velocities set to 0 or estimate if you prefer\n",
    "            initialized = True\n",
    "        \n",
    "        # Kalman Filter: UPDATE step (if we have a new measurement)\n",
    "        if measurement is not None and initialized:\n",
    "            z = np.array([measurement[0], measurement[1]], dtype=float)\n",
    "            \n",
    "            # Compute predicted measurement for innovation\n",
    "            z_pred = kf.H @ kf.x  # or kf.H.dot(kf.x)\n",
    "            innovation = z - z_pred  # y = z - Hx\n",
    "            # Store the norm of the 2D innovation\n",
    "            innovation_magnitude = np.linalg.norm(innovation)\n",
    "            innovation_norms.append(innovation_magnitude)\n",
    "            \n",
    "            # Now update the filter with the actual measurement\n",
    "            kf.update(z)\n",
    "        else:\n",
    "            # If there's no measurement, we only have the prediction\n",
    "            # or we're not yet initialized, so no update\n",
    "            innovation_norms.append(None)  # No innovation for this step\n",
    "        \n",
    "        # --- 4. Draw the filtered centroid on the frame ---\n",
    "        frame_path = os.path.join(processed_folder, f\"frame_{i:06d}.jpg\")\n",
    "        frame = cv2.imread(frame_path)\n",
    "        if frame is None:\n",
    "            continue\n",
    "        \n",
    "        # Get the filters current best estimate (x, y)\n",
    "        x_est, y_est, vx_est, vy_est = kf.x\n",
    "        if initialized:\n",
    "            # Draw a circle for the Kalman-estimated position\n",
    "            cv2.circle(frame, (int(x_est), int(y_est)), 6, (0, 0, 255), -1)  # red circle\n",
    "            cv2.putText(frame, \"KF\",\n",
    "                        (int(x_est) + 10, int(y_est)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        \n",
    "        # Optionally, also draw the raw YOLO measurement in a different color\n",
    "        if measurement is not None:\n",
    "            cv2.circle(frame, (int(measurement[0]), int(measurement[1])), 4, (255, 0, 0), -1)  # blue\n",
    "        \n",
    "        # Save the new frame with Kalman annotation\n",
    "        out_path = os.path.join(kalman_folder, f\"frame_{i:06d}.jpg\")\n",
    "        cv2.imwrite(out_path, frame)\n",
    "    \n",
    "    # 5) Rebuild the annotated video\n",
    "    output_video = \"kalman_output_video.mp4\"\n",
    "    rebuild_video(kalman_folder, output_video, total_frames, fps=30)\n",
    "    \n",
    "    print(\"Kalman filtering complete. Innovation norms:\", innovation_norms)\n",
    "    print(f\"Output video saved to: {output_video}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalman filtering complete. Innovation norms: [None, None, None, None, None, None, None, None, None, None, None, 0.0, 1.0, None, None, None, None, None, None, None, None, None, None, None, None, None, 5.073767866125884, None, 0.5614483804855502, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 6.908589665459108, 2.543529730024819, None, None, None, None, None, None, 5.808801483744184, 4.096273009382025, 2.7973894043281677, 2.9787631137337294, 2.277730526855013, 2.6891516640531337, 2.1661533193347795, 2.6431223544431695, 2.1828726869439805, 1.8052554109685062, None, None, None, None, None, None, None, None, None, None, None, 0.5089902345051298, 0.2764601530394146, 0.1272960391571221, 0.08443738284337128, 1.508967004486005, 0.6892382261746632, 0.8453214660690003, 1.681709304386929, 1.6654256194857813, 1.286975006321671, 2.078119614679071, 2.028694934401208, 1.9984739136657628, 1.9270511933645975, 1.54665039202966, 2.069125261129234, 1.460985894391161, 2.2978607979008445, 2.829372932868798, 2.159093303302356, 2.975708743421028, 2.0186821078926465, 2.641904160540869, None, None, None, None, None, None, None, None, None, None, 7.805517641943227, 6.887661497229457, 6.361112548588771, 6.800851531034678, None, None, None, None, 7.319519699832645, None, 7.273062747796342, 6.607946095688654, 6.977202035511607, 7.006285952077384, 6.389209928011978, 5.531399820187922, None, None, None, 5.523602150977191, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 11.644156021984855, 6.8776227020708465, 5.948395028142189, None, 5.1508565539342435, 4.503089726672975, None, None, 4.7366555044833385, 5.099186271634108, 4.178449205533025, 3.675267188341626, 3.3252991548796214, 3.849052754733299, 3.0997519449564694, 3.373747668747823, 2.9243788894091947, 3.269366128868226, 3.6989427298927855, 3.935408239076595, 4.895988724026463, 4.0067154007077415, 3.7292030867301174, 4.290118518056994, 3.986314196263815, 3.682604082542854, 3.9773971125807654, 4.093456126907749, 3.204346134422162, 2.1250703945414138, 3.3968809828975437, None, None, None, None, 5.554299112267101, 5.075125796675638, 5.033123399313929, 5.252513532687714, 6.141288438899531, None, 7.145025207174689, 6.116186744916772, 7.072872964243032, 5.990499790648892, 6.33179094864948, None, None, None, None, None, None, 9.819317870471911, 9.929335408568212, 10.302514207078207, 10.289268057982442, 12.444306432572198, 11.781849710548803, 11.668820091308934, 11.674292853590858, 11.61380182617462, 12.235446246044054, 10.836843149763798, 11.621965548774197, 11.951315458582046, 11.86244112108953, 13.200555274279377, None, 14.103593151691118, None, 14.716338182607187, 14.009626111625684, 14.290719959652764, 13.683056954161083, 13.972126072478623, 14.265280609261339, 15.015807056258934, 14.850919476817927, 14.200621916161795, 14.494718743185379, 14.782922501630466, 14.176162740323765, 14.470494973742767, 13.872920864526105, 14.180616833103745, 14.945229302798781, 15.21825081139765, 14.60359415070736, 14.505811104524103, 14.76064666329101, 14.662419403381179, 14.903415600641575, 14.791710811203933, 14.15143830826136, 14.463614027850866, 13.8822843453068, 14.194733922339186, 13.61691426273914, 14.407592032270925, 13.370880951752481, 14.614205633142076, 14.47751907915059, 14.329126640011149, 13.724810382952771, 14.050482657971482, 13.48046424862521, 13.807159397281557, 12.364001682832551, 12.293152086940127, 13.063685204342432, 12.508850896800634, 11.170800356659793, 11.454772726644128, 10.939936490945323, 11.816551921447363, 10.786989601119178, None, None, None, 3.6301866703044836, None, None, 8.275811890795024, 6.642540833385581, 6.760674761416546, 6.195974275963506, None, 5.1811135847295615, 4.608581386453219, 4.044545759688374, 3.395781143641908, 3.0247060186522012, None, 4.851895196451136, 2.998931464497047, None, None, None, None, None, None, None, None, None, None, None, 8.27436141582244, 5.99229736956983, 5.263354099898194, 8.296196282705907, 9.61266511979772, 10.025978664784123, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "Output video saved to: kalman_output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "#run main\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Count Vehicular Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/VisDrone2019-DET-train.zip to 'datasets/VisDrone/VisDrone2019-DET-train.zip'...\n",
      "Downloading https://ultralytics.com/assets/VisDrone2019-DET-val.zip to 'datasets/VisDrone/VisDrone2019-DET-val.zip'...\n",
      "Downloading https://ultralytics.com/assets/VisDrone2019-DET-test-dev.zip to 'datasets/VisDrone/VisDrone2019-DET-test-dev.zip'...\n",
      "Downloading https://ultralytics.com/assets/VisDrone2019-DET-test-challenge.zip to 'datasets/VisDrone/VisDrone2019-DET-test-challenge.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/VisDrone/VisDrone2019-DET-train: 6471it [01:02, 102.79it/s]\n",
      "Converting datasets/VisDrone/VisDrone2019-DET-val: 548it [00:07, 77.90it/s] \n",
      "Converting datasets/VisDrone/VisDrone2019-DET-test-dev: 1610it [00:15, 104.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from ultralytics.utils.downloads import download\n",
    "\n",
    "\n",
    "\n",
    "# Download VisDrone Dataset\n",
    "dir = Path(\"./datasets/VisDrone\")  # dataset root dir\n",
    "\n",
    "def visdrone2yolo(dir):\n",
    "    \"\"\"Convert VisDrone annotations to YOLO format, creating label files with normalized bounding box coordinates.\"\"\"\n",
    "    from PIL import Image\n",
    "    from tqdm import tqdm\n",
    "    def convert_box(size, box):\n",
    "        # Convert VisDrone box to YOLO xywh box\n",
    "        dw = 1.0 / size[0]\n",
    "        dh = 1.0 / size[1]\n",
    "        return (box[0] + box[2] / 2) * dw, (box[1] + box[3] / 2) * dh, box[2] * dw, box[3] * dh\n",
    "    (dir / \"labels\").mkdir(parents=True, exist_ok=True)  # make labels directory\n",
    "    pbar = tqdm((dir / \"annotations\").glob(\"*.txt\"), desc=f\"Converting {dir}\")\n",
    "    for f in pbar:\n",
    "        img_size = Image.open((dir / \"images\" / f.name).with_suffix(\".jpg\")).size\n",
    "        lines = []\n",
    "        with open(f, encoding=\"utf-8\") as file:  # read annotation.txt\n",
    "            for row in [x.split(\",\") for x in file.read().strip().splitlines()]:\n",
    "                if row[4] == \"0\":  # VisDrone 'ignored regions' class 0\n",
    "                    continue\n",
    "                cls = int(row[5]) - 1\n",
    "                box = convert_box(img_size, tuple(map(int, row[:4])))\n",
    "                lines.append(f\"{cls} {' '.join(f'{x:.6f}' for x in box)}\\n\")\n",
    "                with open(str(f).replace(f\"{os.sep}annotations{os.sep}\", f\"{os.sep}labels{os.sep}\"), \"w\", encoding=\"utf-8\") as fl:\n",
    "                    fl.writelines(lines)  # write label.txt\n",
    "\n",
    "urls = [\n",
    "    \"https://github.com/ultralytics/assets/releases/download/v0.0.0/VisDrone2019-DET-train.zip\",\n",
    "    \"https://github.com/ultralytics/assets/releases/download/v0.0.0/VisDrone2019-DET-val.zip\",\n",
    "    \"https://github.com/ultralytics/assets/releases/download/v0.0.0/VisDrone2019-DET-test-dev.zip\",\n",
    "    \"https://github.com/ultralytics/assets/releases/download/v0.0.0/VisDrone2019-DET-test-challenge.zip\",\n",
    "]\n",
    "download(urls, dir=dir, curl=True, threads=4)\n",
    "# Convert\n",
    "for d in \"VisDrone2019-DET-train\", \"VisDrone2019-DET-val\", \"VisDrone2019-DET-test-dev\":\n",
    "    visdrone2yolo(dir / d)  # convert VisDrone annotations to YOLO labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Simple Centroid Tracker Class\n",
    "#\n",
    "class CentroidTracker:\n",
    "    def __init__(self, maxDisappeared=50, maxDistance=50):\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = {}      # objectID -> current centroid (x, y)\n",
    "        self.disappeared = {}  # objectID -> consecutive frame count without detection\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "        self.maxDistance = maxDistance\n",
    "        self.tracks = {}       # objectID -> list of centroids (history)\n",
    "        self.counted = {}      # objectID -> boolean flag if already counted\n",
    "\n",
    "    def register(self, centroid):\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.tracks[self.nextObjectID] = [centroid]\n",
    "        self.counted[self.nextObjectID] = False\n",
    "        self.nextObjectID += 1\n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "        del self.tracks[objectID]\n",
    "        del self.counted[objectID]\n",
    "\n",
    "    def update(self, inputCentroids):\n",
    "        # If no new centroids, mark all existing objects as disappeared.\n",
    "        if len(inputCentroids) == 0:\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "            return self.objects\n",
    "\n",
    "        # If no objects are currently tracked, register all input centroids.\n",
    "        if len(self.objects) == 0:\n",
    "            for centroid in inputCentroids:\n",
    "                self.register(centroid)\n",
    "            return self.objects\n",
    "\n",
    "        # Compute distance between each existing object and new centroid.\n",
    "        objectIDs = list(self.objects.keys())\n",
    "        objectCentroids = list(self.objects.values())\n",
    "        D = np.linalg.norm(\n",
    "            np.array(objectCentroids)[:, np.newaxis] - np.array(inputCentroids),\n",
    "            axis=2\n",
    "        )\n",
    "\n",
    "        # Find the smallest distances and match them.\n",
    "        rows = D.min(axis=1).argsort()\n",
    "        cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "        usedRows = set()\n",
    "        usedCols = set()\n",
    "\n",
    "        for (row, col) in zip(rows, cols):\n",
    "            if row in usedRows or col in usedCols:\n",
    "                continue\n",
    "            if D[row, col] > self.maxDistance:\n",
    "                continue\n",
    "            objectID = objectIDs[row]\n",
    "            self.objects[objectID] = inputCentroids[col]\n",
    "            self.tracks[objectID].append(inputCentroids[col])\n",
    "            self.disappeared[objectID] = 0\n",
    "            usedRows.add(row)\n",
    "            usedCols.add(col)\n",
    "\n",
    "        # Mark unmatched existing objects as disappeared.\n",
    "        unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "        for row in unusedRows:\n",
    "            objectID = objectIDs[row]\n",
    "            self.disappeared[objectID] += 1\n",
    "            if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                self.deregister(objectID)\n",
    "\n",
    "        # Register new objects for unmatched input centroids.\n",
    "        unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "        for col in unusedCols:\n",
    "            self.register(inputCentroids[col])\n",
    "\n",
    "        return self.objects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(\"../../runs/mlflow/647870279470109661/99b156ce37314ea9af73e146223fc2f3/artifacts/weights/best.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames extracted: 726\n",
      "\n",
      "0: 288x512 12 cars, 2 vans, 1 truck, 25.3ms\n",
      "Speed: 3.0ms preprocess, 25.3ms inference, 3.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 2 vans, 1 truck, 23.3ms\n",
      "Speed: 3.5ms preprocess, 23.3ms inference, 3.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 4 vans, 1 truck, 22.5ms\n",
      "Speed: 2.9ms preprocess, 22.5ms inference, 3.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 cars, 1 van, 1 truck, 22.4ms\n",
      "Speed: 2.6ms preprocess, 22.4ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 2 vans, 1 truck, 19.9ms\n",
      "Speed: 2.1ms preprocess, 19.9ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 1 van, 1 truck, 18.5ms\n",
      "Speed: 2.3ms preprocess, 18.5ms inference, 3.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 2 vans, 1 truck, 18.0ms\n",
      "Speed: 1.9ms preprocess, 18.0ms inference, 2.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 1 van, 1 truck, 17.9ms\n",
      "Speed: 2.1ms preprocess, 17.9ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 1 van, 1 truck, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 2.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 1 van, 1 truck, 18.2ms\n",
      "Speed: 2.2ms preprocess, 18.2ms inference, 2.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 1 van, 1 truck, 10.9ms\n",
      "Speed: 1.2ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 1 van, 1 truck, 14.6ms\n",
      "Speed: 1.8ms preprocess, 14.6ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 1 van, 1 truck, 10.8ms\n",
      "Speed: 1.8ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 1 van, 1 truck, 12.2ms\n",
      "Speed: 2.1ms preprocess, 12.2ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 1 van, 1 truck, 11.0ms\n",
      "Speed: 1.8ms preprocess, 11.0ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 1 van, 1 truck, 13.4ms\n",
      "Speed: 1.7ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 1 truck, 13.1ms\n",
      "Speed: 1.6ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 1 truck, 10.8ms\n",
      "Speed: 1.8ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 1 truck, 10.9ms\n",
      "Speed: 1.9ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 1 truck, 13.4ms\n",
      "Speed: 2.3ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 1 van, 1 truck, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 1 truck, 14.0ms\n",
      "Speed: 1.7ms preprocess, 14.0ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 1 truck, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 1 truck, 13.8ms\n",
      "Speed: 1.5ms preprocess, 13.8ms inference, 4.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 1 van, 1 truck, 11.9ms\n",
      "Speed: 1.6ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 1 truck, 10.4ms\n",
      "Speed: 1.5ms preprocess, 10.4ms inference, 3.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 1 truck, 13.8ms\n",
      "Speed: 1.9ms preprocess, 13.8ms inference, 5.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 1 truck, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 1 truck, 13.3ms\n",
      "Speed: 1.5ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 2 vans, 1 truck, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 2 trucks, 10.4ms\n",
      "Speed: 1.6ms preprocess, 10.4ms inference, 3.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 2 trucks, 11.3ms\n",
      "Speed: 1.8ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 3 trucks, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 1 van, 2 trucks, 10.7ms\n",
      "Speed: 1.8ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 2 trucks, 11.2ms\n",
      "Speed: 1.7ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 1 truck, 11.8ms\n",
      "Speed: 1.8ms preprocess, 11.8ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 2 trucks, 9.7ms\n",
      "Speed: 1.2ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 1 van, 1 truck, 10.6ms\n",
      "Speed: 1.7ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 truck, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 truck, 13.3ms\n",
      "Speed: 1.7ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 1 truck, 11.0ms\n",
      "Speed: 1.7ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 trucks, 9.9ms\n",
      "Speed: 1.8ms preprocess, 9.9ms inference, 3.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 2 trucks, 13.8ms\n",
      "Speed: 1.6ms preprocess, 13.8ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 2 trucks, 12.2ms\n",
      "Speed: 1.7ms preprocess, 12.2ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 trucks, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 trucks, 9.9ms\n",
      "Speed: 2.0ms preprocess, 9.9ms inference, 3.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 trucks, 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 trucks, 13.0ms\n",
      "Speed: 1.7ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 2 trucks, 15.0ms\n",
      "Speed: 1.8ms preprocess, 15.0ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 trucks, 15.1ms\n",
      "Speed: 1.4ms preprocess, 15.1ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 17 cars, 2 trucks, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 trucks, 11.0ms\n",
      "Speed: 1.6ms preprocess, 11.0ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 trucks, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 trucks, 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 trucks, 16.0ms\n",
      "Speed: 1.7ms preprocess, 16.0ms inference, 2.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 trucks, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 trucks, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 trucks, 9.6ms\n",
      "Speed: 1.6ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 16 cars, 2 trucks, 12.3ms\n",
      "Speed: 2.5ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 1 van, 2 trucks, 13.7ms\n",
      "Speed: 2.5ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 2 trucks, 13.7ms\n",
      "Speed: 2.7ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 2 trucks, 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 2 trucks, 12.4ms\n",
      "Speed: 1.8ms preprocess, 12.4ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 2 trucks, 10.7ms\n",
      "Speed: 1.6ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 2 trucks, 11.5ms\n",
      "Speed: 1.7ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 2 trucks, 9.6ms\n",
      "Speed: 1.7ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 2 trucks, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 2 trucks, 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 3 trucks, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 2 trucks, 9.6ms\n",
      "Speed: 1.6ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 2 trucks, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 2.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 2 trucks, 11.2ms\n",
      "Speed: 1.9ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 2 trucks, 13.9ms\n",
      "Speed: 2.1ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 3 trucks, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 2 trucks, 12.0ms\n",
      "Speed: 1.7ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 3 trucks, 9.2ms\n",
      "Speed: 1.4ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 16 cars, 2 trucks, 9.7ms\n",
      "Speed: 1.9ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 16 cars, 3 trucks, 10.3ms\n",
      "Speed: 1.5ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 16 cars, 1 van, 2 trucks, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 3 trucks, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 1 van, 4 trucks, 11.8ms\n",
      "Speed: 1.5ms preprocess, 11.8ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 4 trucks, 9.6ms\n",
      "Speed: 1.9ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 5 trucks, 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 4 trucks, 10.1ms\n",
      "Speed: 1.7ms preprocess, 10.1ms inference, 2.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 3 trucks, 9.8ms\n",
      "Speed: 1.8ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 4 trucks, 12.2ms\n",
      "Speed: 1.7ms preprocess, 12.2ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 4 trucks, 16.7ms\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 4 trucks, 14.7ms\n",
      "Speed: 1.6ms preprocess, 14.7ms inference, 3.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 3 trucks, 13.2ms\n",
      "Speed: 1.7ms preprocess, 13.2ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 5 trucks, 13.6ms\n",
      "Speed: 1.8ms preprocess, 13.6ms inference, 2.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 4 trucks, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 4 trucks, 9.3ms\n",
      "Speed: 1.7ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 5 trucks, 11.5ms\n",
      "Speed: 1.6ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 5 trucks, 11.7ms\n",
      "Speed: 2.1ms preprocess, 11.7ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 4 trucks, 9.9ms\n",
      "Speed: 2.0ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 4 trucks, 9.3ms\n",
      "Speed: 1.8ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 6 trucks, 10.7ms\n",
      "Speed: 1.9ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 5 trucks, 9.2ms\n",
      "Speed: 1.9ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 2 vans, 5 trucks, 9.3ms\n",
      "Speed: 1.3ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 5 trucks, 10.8ms\n",
      "Speed: 1.9ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 4 trucks, 9.0ms\n",
      "Speed: 1.7ms preprocess, 9.0ms inference, 3.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 6 trucks, 11.2ms\n",
      "Speed: 1.9ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 4 trucks, 11.3ms\n",
      "Speed: 1.6ms preprocess, 11.3ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 5 trucks, 1 bus, 22.7ms\n",
      "Speed: 1.6ms preprocess, 22.7ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 2 vans, 3 trucks, 1 bus, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 3 trucks, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 3 trucks, 9.4ms\n",
      "Speed: 1.6ms preprocess, 9.4ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 4 trucks, 9.4ms\n",
      "Speed: 2.2ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 5 trucks, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 4 trucks, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 5 trucks, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 3 trucks, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 3 trucks, 1 bus, 11.3ms\n",
      "Speed: 2.0ms preprocess, 11.3ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 3 trucks, 1 bus, 9.9ms\n",
      "Speed: 2.0ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 1 van, 3 trucks, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 3 trucks, 9.6ms\n",
      "Speed: 1.9ms preprocess, 9.6ms inference, 3.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 4 trucks, 9.5ms\n",
      "Speed: 1.8ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 3 trucks, 13.1ms\n",
      "Speed: 1.7ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 3 trucks, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 4 trucks, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 3 trucks, 1 bus, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 4 trucks, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 4 trucks, 9.0ms\n",
      "Speed: 2.1ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 4 trucks, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 4.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 4 trucks, 9.1ms\n",
      "Speed: 2.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 4 trucks, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 1 van, 4 trucks, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 4 trucks, 10.0ms\n",
      "Speed: 1.4ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 3 trucks, 9.8ms\n",
      "Speed: 2.1ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 1 van, 2 trucks, 14.1ms\n",
      "Speed: 1.6ms preprocess, 14.1ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 cars, 3 trucks, 10.9ms\n",
      "Speed: 1.7ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 3 trucks, 12.4ms\n",
      "Speed: 1.6ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 cars, 3 trucks, 9.5ms\n",
      "Speed: 2.1ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 3 trucks, 12.7ms\n",
      "Speed: 1.6ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 3 trucks, 9.0ms\n",
      "Speed: 2.1ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 cars, 1 van, 4 trucks, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 3.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 10 cars, 1 van, 3 trucks, 12.1ms\n",
      "Speed: 1.8ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 11 cars, 3 trucks, 11.3ms\n",
      "Speed: 2.0ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 2 trucks, 14.5ms\n",
      "Speed: 1.6ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 12 cars, 3 trucks, 13.9ms\n",
      "Speed: 1.6ms preprocess, 13.9ms inference, 3.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 3 trucks, 9.1ms\n",
      "Speed: 1.8ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 5 trucks, 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 2.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 3 trucks, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 2 trucks, 9.9ms\n",
      "Speed: 1.7ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 1 van, 2 trucks, 8.8ms\n",
      "Speed: 1.5ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 16 cars, 4 trucks, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 3.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 4 trucks, 1 bus, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 4 trucks, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 3 trucks, 9.3ms\n",
      "Speed: 2.0ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 2 trucks, 8.7ms\n",
      "Speed: 1.9ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 1 van, 4 trucks, 12.1ms\n",
      "Speed: 1.7ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 1 van, 3 trucks, 9.3ms\n",
      "Speed: 2.1ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 2 trucks, 1 bus, 11.4ms\n",
      "Speed: 1.9ms preprocess, 11.4ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 1 van, 1 truck, 14.7ms\n",
      "Speed: 1.9ms preprocess, 14.7ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 3 trucks, 8.8ms\n",
      "Speed: 1.7ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 2 trucks, 14.0ms\n",
      "Speed: 1.7ms preprocess, 14.0ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 1 van, 2 trucks, 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 1 van, 2 trucks, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 2 trucks, 15.1ms\n",
      "Speed: 1.7ms preprocess, 15.1ms inference, 2.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 2 trucks, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 17 cars, 1 van, 2 trucks, 8.9ms\n",
      "Speed: 1.8ms preprocess, 8.9ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 3 trucks, 9.3ms\n",
      "Speed: 1.7ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 2 trucks, 13.2ms\n",
      "Speed: 1.6ms preprocess, 13.2ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 trucks, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 3 trucks, 10.2ms\n",
      "Speed: 1.5ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 16 cars, 2 trucks, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 3 trucks, 10.1ms\n",
      "Speed: 1.6ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 3 trucks, 11.3ms\n",
      "Speed: 1.9ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 2 trucks, 8.8ms\n",
      "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 2 vans, 2 trucks, 13.5ms\n",
      "Speed: 1.7ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 3 trucks, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 3 trucks, 9.2ms\n",
      "Speed: 1.6ms preprocess, 9.2ms inference, 3.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 3 trucks, 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 1 van, 4 trucks, 13.2ms\n",
      "Speed: 1.5ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 3 trucks, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 3 trucks, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 3 trucks, 8.8ms\n",
      "Speed: 2.0ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 3 trucks, 1 bus, 11.0ms\n",
      "Speed: 1.6ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 4 trucks, 22.4ms\n",
      "Speed: 1.5ms preprocess, 22.4ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 3 trucks, 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 3.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 4 trucks, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 4 trucks, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 5 trucks, 14.4ms\n",
      "Speed: 2.4ms preprocess, 14.4ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 4 trucks, 8.8ms\n",
      "Speed: 1.7ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 4 trucks, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 4 trucks, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 2.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 4 trucks, 10.8ms\n",
      "Speed: 1.6ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 3 trucks, 9.6ms\n",
      "Speed: 1.7ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 5 trucks, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 4 trucks, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 1 van, 3 trucks, 1 bus, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 4 trucks, 13.9ms\n",
      "Speed: 1.8ms preprocess, 13.9ms inference, 2.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 4 trucks, 10.3ms\n",
      "Speed: 1.6ms preprocess, 10.3ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 15 cars, 5 trucks, 1 bus, 12.7ms\n",
      "Speed: 2.5ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 2 vans, 4 trucks, 1 bus, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 1 van, 4 trucks, 1 bus, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 13 cars, 1 van, 4 trucks, 2 buss, 10.0ms\n",
      "Speed: 1.2ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 14 cars, 3 trucks, 2 buss, 8.9ms\n",
      "Speed: 2.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39mboxes:\n\u001b[0;32m---> 63\u001b[0m         cls_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m         label \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mnames[cls_idx]\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m vehicle_labels:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Main Vehicle Counting Pipeline Using Ultralytics YOLO\n",
    "\n",
    "video_path = \"Assignment3_Task3_video.mp4\"    \n",
    "frames_folder = \"extracted_frames_car_count\"  \n",
    "processed_folder = \"processed_frames_car_count\"  \n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "# 2) Split video into frames\n",
    "total_frames = split_video_to_frames(video_path, frames_folder)\n",
    "print(f\"Total frames extracted: {total_frames}\")\n",
    "\n",
    "\n",
    "# 3) Get frame dimensions from the first frame\n",
    "first_frame_path = os.path.join(frames_folder, \"frame_000000.jpg\")\n",
    "first_frame = cv2.imread(first_frame_path)\n",
    "if first_frame is None:\n",
    "    raise RuntimeError(\"Could not load the first frame.\")\n",
    "height, width, _ = first_frame.shape\n",
    "\n",
    "\n",
    "# 4) Define the counting line (vertical line across the frame)\n",
    "# Placed at the midpoint of the width for left-right counting\n",
    "line_x = int(width * 0.5)\n",
    "\n",
    "\n",
    "# 5) Load YOLO model with fine-tuned weights\n",
    "#  \n",
    "model = YOLO(\"../../runs/mlflow/647870279470109661/99b156ce37314ea9af73e146223fc2f3/artifacts/weights/best.pt\")\n",
    "vehicle_labels = {\"car\", \"truck\", \"bus\", \"motorcycle\", \"motorbike\"}\n",
    "# 6) Initialize the centroid tracker and counters\n",
    "\n",
    "ct = CentroidTracker(maxDisappeared=30, maxDistance=50)\n",
    "count_left = 0   # Vehicles moving left  (x > line_x -> x <= line_x)\n",
    "count_right = 0  # Vehicles moving right (x < line_x -> x >= line_x)\n",
    "\n",
    "# For time series data\n",
    "time_series = []\n",
    "counts_left_series = []\n",
    "counts_right_series = []\n",
    "\n",
    "\n",
    "# 7) Retrieve fps from the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "cap.release()\n",
    "duration = total_frames / fps\n",
    "\n",
    "\n",
    "# 8) Process each extracted frame\n",
    "for i in range(total_frames):\n",
    "    frame_path = os.path.join(frames_folder, f\"frame_{i:06d}.jpg\")\n",
    "    frame = cv2.imread(frame_path)\n",
    "    if frame is None:\n",
    "        continue\n",
    "\n",
    "    # Run YOLO detection on the frame\n",
    "    results = model(frame, conf=0.25)\n",
    "    centroids = []\n",
    "\n",
    "    # Extract bounding boxes for relevant classes\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            cls_idx = int(box.cls[0])\n",
    "            label = r.names[cls_idx]\n",
    "            if label in vehicle_labels:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                cx = (x1 + x2) // 2\n",
    "                cy = (y1 + y2) // 2\n",
    "                centroids.append((cx, cy))\n",
    "                # Draw bounding box and centroid\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "\n",
    "    # Update the centroid tracker\n",
    "    objects = ct.update(centroids)\n",
    "\n",
    "    # Check each tracked object for crossing the vertical line\n",
    "    for objectID, centroid in objects.items():\n",
    "        track = ct.tracks.get(objectID, [])\n",
    "        if len(track) >= 2:\n",
    "            prev_x = track[-2][0]\n",
    "            curr_x = track[-1][0]\n",
    "            if not ct.counted[objectID]:\n",
    "                # If the object moved from left to right\n",
    "                if prev_x < line_x and curr_x >= line_x:\n",
    "                    count_right += 1\n",
    "                    ct.counted[objectID] = True\n",
    "                # If the object moved from right to left\n",
    "                elif prev_x > line_x and curr_x <= line_x:\n",
    "                    count_left += 1\n",
    "                    ct.counted[objectID] = True\n",
    "                    \n",
    "        # Label the tracked object on the frame\n",
    "        cv2.putText(frame, f\"ID {objectID}\", (centroid[0]-10, centroid[1]-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        cv2.circle(frame, (centroid[0], centroid[1]), 4, (255, 255, 0), -1)\n",
    "\n",
    "\n",
    "    # Draw the vertical counting line\n",
    "    cv2.line(frame, (line_x, 0), (line_x, height), (0, 0, 255), 2)\n",
    "\n",
    "    # Record counts for time series\n",
    "    time_series.append(i / fps)\n",
    "    counts_left_series.append(count_left)\n",
    "    counts_right_series.append(count_right)\n",
    "\n",
    "\n",
    "    # Save the annotated frame\n",
    "    cv2.imwrite(os.path.join(processed_folder, f\"frame_{i:06d}.jpg\"), frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Duration (s): 30.28025\n",
      "Vehicles moving up: 1 Normalized: 0.033024826413256166\n",
      "Vehicles moving down: 7 Normalized: 0.23117378489279317\n"
     ]
    }
   ],
   "source": [
    "# 7) Normalize the counts by video duration\n",
    "normalized_count_up = count_up / duration\n",
    "normalized_count_down = count_down / duration\n",
    "\n",
    "print(\"Video Duration (s):\", duration)\n",
    "print(\"Vehicles moving up:\", count_up, \"Normalized:\", normalized_count_up)\n",
    "print(\"Vehicles moving down:\", count_down, \"Normalized:\", normalized_count_down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8) Plot the counts over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_series, counts_up_series, label=\"Vehicles Up\")\n",
    "plt.plot(time_series, counts_down_series, label=\"Vehicles Down\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Vehicle Count\")\n",
    "plt.title(\"Vehicle Counts Over Time\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Rye - assignment_3)",
   "language": "python",
   "name": "assignment_3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
