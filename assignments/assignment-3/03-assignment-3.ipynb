{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 - Object Detection\n",
    "By: Alec Pippas (awp251)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Object Detection of Car in Short Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video_to_frames(video_path, frames_folder):\n",
    "    \"\"\"\n",
    "    Splits a video into frames and saves them into the specified folder.\n",
    "    \"\"\"\n",
    "    os.makedirs(frames_folder, exist_ok=True)\n",
    "    captured_vid = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        #reads one frame per iteration, .read() returns a tuple (ret, frame)\n",
    "        # ret: boolean indicating if frame was successfully read\n",
    "        # frame: frame image stored as NumPy array\n",
    "        ret, frame = captured_vid.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imwrite(os.path.join(frames_folder, f'frame_{frame_count:06d}.jpg'), frame) # save current frame withi the frames_folder\n",
    "        frame_count += 1\n",
    "\n",
    "    #free up resources (file handles, memory) associated with the cv2.VideoCaptuer object\n",
    "    captured_vid.release() \n",
    "    return frame_count\n",
    "\n",
    "\n",
    "\n",
    "def detect_and_annotate(frames_folder, processed_folder, model, total_frames, csv_file=\"detections.csv\"):\n",
    "    \"\"\"\n",
    "    Performs object detection on each frame using a YOLO model,\n",
    "    draws bounding boxes (for cars) with centroids, saves new frames,\n",
    "    and logs the car centroids to a CSV.\n",
    "    \"\"\"\n",
    "    os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "    # Open CSV for writing all detections (frame_idx, conf, cx, cy)\n",
    "    with open(csv_file, mode=\"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        # Write a header row (customize as you like)\n",
    "        writer.writerow([\"frame_idx\", \"conf\", \"cx\", \"cy\"])\n",
    "\n",
    "        for i in range(total_frames):\n",
    "            frame_path = os.path.join(frames_folder, f'frame_{i:06d}.jpg')\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                continue\n",
    "\n",
    "            # Run object detection\n",
    "            results = model(frame)  # Optionally: model(frame, conf=0.6)\n",
    "\n",
    "            # Draw bounding boxes and centroids\n",
    "            for r in results:\n",
    "                for box in r.boxes:\n",
    "                    class_idx = int(box.cls[0])  # predicted class index\n",
    "                    label = r.names[class_idx]   # class label (e.g., \"car\")\n",
    "                    if label == \"car\":\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                        conf = float(box.conf[0])\n",
    "\n",
    "                        # Draw bounding box\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "                        # Class label + confidence\n",
    "                        text = f\"{label} {conf:.2f}\"\n",
    "                        cv2.putText(frame, text, (x1, y1 - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                        # Compute and draw centroid\n",
    "                        cx = (x1 + x2) // 2\n",
    "                        cy = (y1 + y2) // 2\n",
    "                        cv2.circle(frame, (cx, cy), 5, (0, 255, 0), -1)\n",
    "\n",
    "                        # Write one row per detection to CSV\n",
    "                        writer.writerow([i, f\"{conf:.2f}\", cx, cy])\n",
    "\n",
    "            # Save the annotated frame\n",
    "            cv2.imwrite(os.path.join(processed_folder, f'frame_{i:06d}.jpg'), frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_video_from_frames(processed_folder, output_video, total_frames, fps=30):\n",
    "    \"\"\"\n",
    "    Rebuilds a video from processed frames.\n",
    "    \"\"\"\n",
    "    # Read the first frame to get size info\n",
    "    first_frame_path = os.path.join(processed_folder, 'frame_000000.jpg')\n",
    "    first_frame = cv2.imread(first_frame_path)\n",
    "    \n",
    "    #raise execption if the frame was not read (may indicate the frame was not extracted/processed correctly)\n",
    "    if first_frame is None:\n",
    "        raise FileNotFoundError(f\"Could not read the file: {first_frame_path}\")\n",
    "\n",
    "    height, width, _ = first_frame.shape\n",
    "\n",
    "    # Create VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  \n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "    # Write each processed frame to the new video\n",
    "    for i in range(total_frames):\n",
    "        processed_frame_path = os.path.join(processed_folder, f'frame_{i:06d}.jpg')\n",
    "        processed_frame = cv2.imread(processed_frame_path)\n",
    "        if processed_frame is not None:\n",
    "            out.write(processed_frame)\n",
    "\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 bus, 44.1ms\n",
      "Speed: 2.3ms preprocess, 44.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 29.7ms\n",
      "Speed: 3.3ms preprocess, 29.7ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 31.3ms\n",
      "Speed: 1.9ms preprocess, 31.3ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 30.1ms\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 8.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 23.5ms\n",
      "Speed: 2.7ms preprocess, 23.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 20.5ms\n",
      "Speed: 1.4ms preprocess, 20.5ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 21.1ms\n",
      "Speed: 1.5ms preprocess, 21.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 22.1ms\n",
      "Speed: 1.7ms preprocess, 22.1ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 19.7ms\n",
      "Speed: 1.7ms preprocess, 19.7ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 17.7ms\n",
      "Speed: 1.9ms preprocess, 17.7ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 15.1ms\n",
      "Speed: 2.3ms preprocess, 15.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 15.6ms\n",
      "Speed: 2.1ms preprocess, 15.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 15.2ms\n",
      "Speed: 1.6ms preprocess, 15.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 15.7ms\n",
      "Speed: 1.8ms preprocess, 15.7ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 19.0ms\n",
      "Speed: 1.5ms preprocess, 19.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 13.2ms\n",
      "Speed: 1.7ms preprocess, 13.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 20.4ms\n",
      "Speed: 1.4ms preprocess, 20.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 train, 17.5ms\n",
      "Speed: 1.4ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 train, 19.5ms\n",
      "Speed: 1.8ms preprocess, 19.5ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 16.4ms\n",
      "Speed: 1.7ms preprocess, 16.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 18.3ms\n",
      "Speed: 2.1ms preprocess, 18.3ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 17.1ms\n",
      "Speed: 2.4ms preprocess, 17.1ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 12.9ms\n",
      "Speed: 1.3ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.2ms\n",
      "Speed: 1.7ms preprocess, 14.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 12.9ms\n",
      "Speed: 1.4ms preprocess, 12.9ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 16.2ms\n",
      "Speed: 1.7ms preprocess, 16.2ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 14.7ms\n",
      "Speed: 1.7ms preprocess, 14.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 train, 13.6ms\n",
      "Speed: 2.1ms preprocess, 13.6ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 27.7ms\n",
      "Speed: 2.2ms preprocess, 27.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 17.1ms\n",
      "Speed: 1.6ms preprocess, 17.1ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 train, 17.6ms\n",
      "Speed: 2.1ms preprocess, 17.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 12.5ms\n",
      "Speed: 2.6ms preprocess, 12.5ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 15.8ms\n",
      "Speed: 2.4ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 13.6ms\n",
      "Speed: 2.7ms preprocess, 13.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 15.6ms\n",
      "Speed: 1.4ms preprocess, 15.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 14.3ms\n",
      "Speed: 1.6ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 14.2ms\n",
      "Speed: 1.5ms preprocess, 14.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 13.3ms\n",
      "Speed: 2.1ms preprocess, 13.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 16.9ms\n",
      "Speed: 2.7ms preprocess, 16.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 train, 1 truck, 13.9ms\n",
      "Speed: 1.6ms preprocess, 13.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 train, 1 truck, 13.5ms\n",
      "Speed: 1.6ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 14.0ms\n",
      "Speed: 1.6ms preprocess, 14.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 16.1ms\n",
      "Speed: 1.6ms preprocess, 16.1ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 17.3ms\n",
      "Speed: 2.3ms preprocess, 17.3ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 14.0ms\n",
      "Speed: 3.1ms preprocess, 14.0ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 19.0ms\n",
      "Speed: 2.1ms preprocess, 19.0ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 15.0ms\n",
      "Speed: 1.7ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 17.9ms\n",
      "Speed: 1.5ms preprocess, 17.9ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 14.6ms\n",
      "Speed: 1.5ms preprocess, 14.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.7ms\n",
      "Speed: 1.9ms preprocess, 13.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 14.2ms\n",
      "Speed: 1.5ms preprocess, 14.2ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 23.1ms\n",
      "Speed: 1.7ms preprocess, 23.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 22.7ms\n",
      "Speed: 2.9ms preprocess, 22.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.5ms\n",
      "Speed: 2.3ms preprocess, 12.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 14.6ms\n",
      "Speed: 1.6ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 12.7ms\n",
      "Speed: 1.7ms preprocess, 12.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 15.7ms\n",
      "Speed: 1.7ms preprocess, 15.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 12.3ms\n",
      "Speed: 1.8ms preprocess, 12.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 14.0ms\n",
      "Speed: 2.4ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 12.4ms\n",
      "Speed: 1.6ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 13.5ms\n",
      "Speed: 1.8ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 21.2ms\n",
      "Speed: 1.8ms preprocess, 21.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 22.6ms\n",
      "Speed: 7.1ms preprocess, 22.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 17.3ms\n",
      "Speed: 2.7ms preprocess, 17.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.8ms\n",
      "Speed: 1.8ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 19.7ms\n",
      "Speed: 2.0ms preprocess, 19.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 19.6ms\n",
      "Speed: 2.0ms preprocess, 19.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.6ms\n",
      "Speed: 1.4ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.2ms\n",
      "Speed: 1.6ms preprocess, 13.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 12.2ms\n",
      "Speed: 3.0ms preprocess, 12.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 14.2ms\n",
      "Speed: 1.9ms preprocess, 14.2ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 12.8ms\n",
      "Speed: 1.5ms preprocess, 12.8ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 14.6ms\n",
      "Speed: 1.4ms preprocess, 14.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 19.1ms\n",
      "Speed: 1.9ms preprocess, 19.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 12.1ms\n",
      "Speed: 1.7ms preprocess, 12.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.7ms\n",
      "Speed: 1.9ms preprocess, 15.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.2ms\n",
      "Speed: 2.1ms preprocess, 13.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.4ms\n",
      "Speed: 1.6ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 17.6ms\n",
      "Speed: 2.1ms preprocess, 17.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.3ms\n",
      "Speed: 2.7ms preprocess, 14.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 train, 14.3ms\n",
      "Speed: 1.9ms preprocess, 14.3ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 17.6ms\n",
      "Speed: 2.2ms preprocess, 17.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.5ms\n",
      "Speed: 2.7ms preprocess, 14.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 16.8ms\n",
      "Speed: 2.5ms preprocess, 16.8ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 21.2ms\n",
      "Speed: 1.7ms preprocess, 21.2ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 18.1ms\n",
      "Speed: 2.1ms preprocess, 18.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.2ms\n",
      "Speed: 1.4ms preprocess, 15.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 19.4ms\n",
      "Speed: 2.0ms preprocess, 19.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 18.8ms\n",
      "Speed: 2.1ms preprocess, 18.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.2ms\n",
      "Speed: 1.7ms preprocess, 15.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.2ms\n",
      "Speed: 1.5ms preprocess, 14.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 14.3ms\n",
      "Speed: 1.8ms preprocess, 14.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 1 truck, 18.7ms\n",
      "Speed: 2.0ms preprocess, 18.7ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 19.6ms\n",
      "Speed: 1.9ms preprocess, 19.6ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.1ms\n",
      "Speed: 1.8ms preprocess, 14.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.2ms\n",
      "Speed: 1.9ms preprocess, 14.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 14.8ms\n",
      "Speed: 1.4ms preprocess, 14.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 12.2ms\n",
      "Speed: 1.9ms preprocess, 12.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 train, 13.5ms\n",
      "Speed: 1.6ms preprocess, 13.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 13.4ms\n",
      "Speed: 1.7ms preprocess, 13.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 13.7ms\n",
      "Speed: 2.2ms preprocess, 13.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 12.6ms\n",
      "Speed: 1.5ms preprocess, 12.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.5ms\n",
      "Speed: 2.9ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.5ms\n",
      "Speed: 1.7ms preprocess, 12.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.7ms\n",
      "Speed: 1.8ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.7ms\n",
      "Speed: 2.4ms preprocess, 15.7ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.7ms\n",
      "Speed: 1.7ms preprocess, 13.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.5ms\n",
      "Speed: 1.8ms preprocess, 13.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.7ms\n",
      "Speed: 1.9ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.1ms\n",
      "Speed: 1.7ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.1ms\n",
      "Speed: 2.5ms preprocess, 12.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.5ms\n",
      "Speed: 1.4ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.8ms\n",
      "Speed: 1.7ms preprocess, 14.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 17.5ms\n",
      "Speed: 1.8ms preprocess, 17.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 17.6ms\n",
      "Speed: 1.5ms preprocess, 17.6ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.1ms\n",
      "Speed: 1.8ms preprocess, 14.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 13.7ms\n",
      "Speed: 3.1ms preprocess, 13.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 15.8ms\n",
      "Speed: 1.9ms preprocess, 15.8ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 12.4ms\n",
      "Speed: 1.8ms preprocess, 12.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 21.4ms\n",
      "Speed: 1.8ms preprocess, 21.4ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 16.8ms\n",
      "Speed: 1.9ms preprocess, 16.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 12.3ms\n",
      "Speed: 2.5ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.9ms\n",
      "Speed: 2.1ms preprocess, 14.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 12.4ms\n",
      "Speed: 1.8ms preprocess, 12.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 1 truck, 15.7ms\n",
      "Speed: 1.9ms preprocess, 15.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 11.2ms\n",
      "Speed: 1.7ms preprocess, 11.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 15.3ms\n",
      "Speed: 1.9ms preprocess, 15.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 13.6ms\n",
      "Speed: 2.1ms preprocess, 13.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 16.1ms\n",
      "Speed: 2.1ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 1 truck, 19.3ms\n",
      "Speed: 1.9ms preprocess, 19.3ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 1 truck, 13.8ms\n",
      "Speed: 1.6ms preprocess, 13.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 16.4ms\n",
      "Speed: 2.4ms preprocess, 16.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 20.9ms\n",
      "Speed: 2.2ms preprocess, 20.9ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 19.1ms\n",
      "Speed: 1.9ms preprocess, 19.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 1 truck, 13.5ms\n",
      "Speed: 1.6ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 21.8ms\n",
      "Speed: 2.3ms preprocess, 21.8ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 20.5ms\n",
      "Speed: 1.8ms preprocess, 20.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 13.8ms\n",
      "Speed: 2.6ms preprocess, 13.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 14.9ms\n",
      "Speed: 1.9ms preprocess, 14.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 13.3ms\n",
      "Speed: 2.8ms preprocess, 13.3ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 13.7ms\n",
      "Speed: 1.9ms preprocess, 13.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 17.0ms\n",
      "Speed: 2.1ms preprocess, 17.0ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 1 truck, 14.1ms\n",
      "Speed: 1.4ms preprocess, 14.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 15.6ms\n",
      "Speed: 2.2ms preprocess, 15.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 train, 1 truck, 13.8ms\n",
      "Speed: 2.0ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.5ms\n",
      "Speed: 1.7ms preprocess, 13.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 14.5ms\n",
      "Speed: 1.6ms preprocess, 14.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 15.9ms\n",
      "Speed: 1.7ms preprocess, 15.9ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 24.2ms\n",
      "Speed: 1.7ms preprocess, 24.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 15.8ms\n",
      "Speed: 1.9ms preprocess, 15.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 20.1ms\n",
      "Speed: 1.7ms preprocess, 20.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 16.0ms\n",
      "Speed: 1.7ms preprocess, 16.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.8ms\n",
      "Speed: 1.8ms preprocess, 13.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 12.6ms\n",
      "Speed: 1.7ms preprocess, 12.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 14.5ms\n",
      "Speed: 1.9ms preprocess, 14.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 14.1ms\n",
      "Speed: 1.6ms preprocess, 14.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 12.2ms\n",
      "Speed: 1.6ms preprocess, 12.2ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 14.6ms\n",
      "Speed: 1.3ms preprocess, 14.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 14.2ms\n",
      "Speed: 1.9ms preprocess, 14.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.2ms\n",
      "Speed: 1.6ms preprocess, 14.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 12.1ms\n",
      "Speed: 1.5ms preprocess, 12.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 17.2ms\n",
      "Speed: 1.7ms preprocess, 17.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.8ms\n",
      "Speed: 1.4ms preprocess, 15.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.8ms\n",
      "Speed: 1.6ms preprocess, 12.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.0ms\n",
      "Speed: 1.7ms preprocess, 12.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.4ms\n",
      "Speed: 2.2ms preprocess, 12.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.5ms\n",
      "Speed: 1.7ms preprocess, 13.5ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.2ms\n",
      "Speed: 3.1ms preprocess, 12.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.2ms\n",
      "Speed: 1.7ms preprocess, 11.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.6ms\n",
      "Speed: 1.8ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.7ms\n",
      "Speed: 1.8ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.5ms\n",
      "Speed: 1.3ms preprocess, 15.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.1ms\n",
      "Speed: 1.8ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 13.5ms\n",
      "Speed: 1.3ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.5ms\n",
      "Speed: 1.5ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.9ms\n",
      "Speed: 2.7ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 12.6ms\n",
      "Speed: 1.4ms preprocess, 12.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.7ms\n",
      "Speed: 1.7ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 15.7ms\n",
      "Speed: 1.7ms preprocess, 15.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 13.3ms\n",
      "Speed: 1.6ms preprocess, 13.3ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.2ms\n",
      "Speed: 2.0ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.6ms\n",
      "Speed: 2.2ms preprocess, 12.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.5ms\n",
      "Speed: 1.4ms preprocess, 14.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.3ms\n",
      "Speed: 1.7ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 15.6ms\n",
      "Speed: 2.6ms preprocess, 15.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 10.1ms\n",
      "Speed: 1.7ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 13.5ms\n",
      "Speed: 1.4ms preprocess, 13.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 12.9ms\n",
      "Speed: 1.6ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.9ms\n",
      "Speed: 1.5ms preprocess, 11.9ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.4ms\n",
      "Speed: 1.4ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.1ms\n",
      "Speed: 1.4ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.3ms\n",
      "Speed: 1.6ms preprocess, 13.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.3ms\n",
      "Speed: 1.2ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.3ms\n",
      "Speed: 1.5ms preprocess, 13.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.2ms\n",
      "Speed: 1.7ms preprocess, 14.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 10.2ms\n",
      "Speed: 1.3ms preprocess, 10.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.8ms\n",
      "Speed: 2.5ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 16.8ms\n",
      "Speed: 1.6ms preprocess, 16.8ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.6ms\n",
      "Speed: 1.4ms preprocess, 14.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 23.6ms\n",
      "Speed: 1.7ms preprocess, 23.6ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 22.0ms\n",
      "Speed: 1.7ms preprocess, 22.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 1 truck, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.8ms\n",
      "Speed: 1.5ms preprocess, 13.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.4ms\n",
      "Speed: 1.3ms preprocess, 13.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.0ms\n",
      "Speed: 1.6ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.2ms\n",
      "Speed: 2.8ms preprocess, 12.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.0ms\n",
      "Speed: 1.7ms preprocess, 14.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 20.5ms\n",
      "Speed: 3.8ms preprocess, 20.5ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 9.9ms\n",
      "Speed: 2.1ms preprocess, 9.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.8ms\n",
      "Speed: 1.6ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.8ms\n",
      "Speed: 1.8ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 10.2ms\n",
      "Speed: 1.4ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 17.3ms\n",
      "Speed: 1.1ms preprocess, 17.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.5ms\n",
      "Speed: 1.6ms preprocess, 15.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.3ms\n",
      "Speed: 1.3ms preprocess, 15.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 10.0ms\n",
      "Speed: 1.7ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.2ms\n",
      "Speed: 1.4ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.8ms\n",
      "Speed: 3.8ms preprocess, 12.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.2ms\n",
      "Speed: 1.6ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.3ms\n",
      "Speed: 1.8ms preprocess, 14.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.9ms\n",
      "Speed: 1.2ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.0ms\n",
      "Speed: 2.2ms preprocess, 13.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 10.3ms\n",
      "Speed: 1.4ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.9ms\n",
      "Speed: 1.2ms preprocess, 11.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.9ms\n",
      "Speed: 1.4ms preprocess, 14.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.6ms\n",
      "Speed: 3.5ms preprocess, 13.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.5ms\n",
      "Speed: 1.4ms preprocess, 13.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.8ms\n",
      "Speed: 2.1ms preprocess, 15.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 19.4ms\n",
      "Speed: 2.4ms preprocess, 19.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.9ms\n",
      "Speed: 2.2ms preprocess, 13.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.2ms\n",
      "Speed: 1.7ms preprocess, 14.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.0ms\n",
      "Speed: 1.4ms preprocess, 15.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.2ms\n",
      "Speed: 1.8ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.9ms\n",
      "Speed: 2.3ms preprocess, 14.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.1ms\n",
      "Speed: 1.5ms preprocess, 13.1ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.3ms\n",
      "Speed: 1.9ms preprocess, 14.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.5ms\n",
      "Speed: 1.7ms preprocess, 13.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.8ms\n",
      "Speed: 1.3ms preprocess, 12.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.5ms\n",
      "Speed: 1.9ms preprocess, 13.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 13.0ms\n",
      "Speed: 1.5ms preprocess, 13.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.4ms\n",
      "Speed: 1.9ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bus, 13.1ms\n",
      "Speed: 1.7ms preprocess, 13.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.6ms\n",
      "Speed: 1.6ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.5ms\n",
      "Speed: 1.6ms preprocess, 11.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.0ms\n",
      "Speed: 1.6ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.9ms\n",
      "Speed: 2.0ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.8ms\n",
      "Speed: 1.8ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.8ms\n",
      "Speed: 1.6ms preprocess, 14.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.5ms\n",
      "Speed: 1.7ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 12.7ms\n",
      "Speed: 1.6ms preprocess, 12.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 13.4ms\n",
      "Speed: 1.7ms preprocess, 13.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 18.7ms\n",
      "Speed: 4.7ms preprocess, 18.7ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 20.1ms\n",
      "Speed: 3.5ms preprocess, 20.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 16.4ms\n",
      "Speed: 2.5ms preprocess, 16.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 17.5ms\n",
      "Speed: 2.6ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 13.9ms\n",
      "Speed: 2.5ms preprocess, 13.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 1 truck, 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.9ms\n",
      "Speed: 2.4ms preprocess, 13.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.4ms\n",
      "Speed: 2.1ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.6ms\n",
      "Speed: 1.6ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 14.6ms\n",
      "Speed: 2.2ms preprocess, 14.6ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 train, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.3ms\n",
      "Speed: 1.6ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.2ms\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.8ms\n",
      "Speed: 1.7ms preprocess, 14.8ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.1ms\n",
      "Speed: 1.6ms preprocess, 15.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 train, 13.4ms\n",
      "Speed: 2.2ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 17.6ms\n",
      "Speed: 1.6ms preprocess, 17.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.3ms\n",
      "Speed: 1.7ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.6ms\n",
      "Speed: 1.7ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.0ms\n",
      "Speed: 1.7ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.6ms\n",
      "Speed: 1.6ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.1ms\n",
      "Speed: 1.7ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.2ms\n",
      "Speed: 1.5ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.6ms\n",
      "Speed: 1.6ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.8ms\n",
      "Speed: 2.4ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.1ms\n",
      "Speed: 1.8ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 14.3ms\n",
      "Speed: 1.4ms preprocess, 14.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.9ms\n",
      "Speed: 1.8ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 12.0ms\n",
      "Speed: 1.6ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.5ms\n",
      "Speed: 2.4ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 12.1ms\n",
      "Speed: 1.6ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.0ms\n",
      "Speed: 1.7ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.5ms\n",
      "Speed: 2.3ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.8ms\n",
      "Speed: 1.6ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.7ms\n",
      "Speed: 1.9ms preprocess, 13.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 14.1ms\n",
      "Speed: 1.7ms preprocess, 14.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.3ms\n",
      "Speed: 1.5ms preprocess, 13.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.2ms\n",
      "Speed: 2.1ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.3ms\n",
      "Speed: 1.6ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.5ms\n",
      "Speed: 1.9ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.3ms\n",
      "Speed: 2.3ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.4ms\n",
      "Speed: 1.9ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.2ms\n",
      "Speed: 1.8ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.3ms\n",
      "Speed: 1.6ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 10.8ms\n",
      "Speed: 1.9ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 12.6ms\n",
      "Speed: 1.5ms preprocess, 12.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 14.9ms\n",
      "Speed: 1.5ms preprocess, 14.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 10.8ms\n",
      "Speed: 1.6ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 14.9ms\n",
      "Speed: 2.1ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 13.0ms\n",
      "Speed: 2.9ms preprocess, 13.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.0ms\n",
      "Speed: 1.6ms preprocess, 14.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 14.3ms\n",
      "Speed: 1.6ms preprocess, 14.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 12.3ms\n",
      "Speed: 1.9ms preprocess, 12.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 12.7ms\n",
      "Speed: 2.0ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.0ms\n",
      "Speed: 2.3ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.0ms\n",
      "Speed: 1.7ms preprocess, 11.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.4ms\n",
      "Speed: 2.2ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.5ms\n",
      "Speed: 1.9ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 11.3ms\n",
      "Speed: 1.7ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 18.4ms\n",
      "Speed: 2.1ms preprocess, 18.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 20.0ms\n",
      "Speed: 1.7ms preprocess, 20.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.8ms\n",
      "Speed: 2.1ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 19.8ms\n",
      "Speed: 2.0ms preprocess, 19.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.5ms\n",
      "Speed: 1.5ms preprocess, 14.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 18.6ms\n",
      "Speed: 1.6ms preprocess, 18.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 25.0ms\n",
      "Speed: 1.5ms preprocess, 25.0ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.3ms\n",
      "Speed: 1.7ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.2ms\n",
      "Speed: 1.3ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.0ms\n",
      "Speed: 1.2ms preprocess, 15.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.6ms\n",
      "Speed: 1.8ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.0ms\n",
      "Speed: 1.4ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.6ms\n",
      "Speed: 1.7ms preprocess, 13.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.8ms\n",
      "Speed: 2.2ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.5ms\n",
      "Speed: 1.7ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 train, 13.1ms\n",
      "Speed: 1.5ms preprocess, 13.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.9ms\n",
      "Speed: 1.8ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.3ms\n",
      "Speed: 1.7ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.7ms\n",
      "Speed: 1.4ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.0ms\n",
      "Speed: 2.4ms preprocess, 14.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.4ms\n",
      "Speed: 1.6ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.3ms\n",
      "Speed: 1.9ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.0ms\n",
      "Speed: 1.4ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.8ms\n",
      "Speed: 1.5ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.6ms\n",
      "Speed: 1.6ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.0ms\n",
      "Speed: 1.6ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.6ms\n",
      "Speed: 1.3ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.2ms\n",
      "Speed: 1.9ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.7ms\n",
      "Speed: 1.5ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.9ms\n",
      "Speed: 1.6ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.9ms\n",
      "Speed: 1.6ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.9ms\n",
      "Speed: 1.6ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.5ms\n",
      "Speed: 1.7ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.3ms\n",
      "Speed: 1.8ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.5ms\n",
      "Speed: 2.8ms preprocess, 14.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.5ms\n",
      "Speed: 3.3ms preprocess, 16.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.7ms\n",
      "Speed: 1.4ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.5ms\n",
      "Speed: 1.8ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 22.9ms\n",
      "Speed: 4.4ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 19.7ms\n",
      "Speed: 2.4ms preprocess, 19.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.6ms\n",
      "Speed: 1.4ms preprocess, 13.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.9ms\n",
      "Speed: 2.2ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.7ms\n",
      "Speed: 1.7ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.4ms\n",
      "Speed: 1.7ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.1ms\n",
      "Speed: 1.4ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.7ms\n",
      "Speed: 1.6ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.9ms\n",
      "Speed: 1.7ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.7ms\n",
      "Speed: 1.6ms preprocess, 14.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.0ms\n",
      "Speed: 1.6ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.3ms\n",
      "Speed: 2.6ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.4ms\n",
      "Speed: 1.4ms preprocess, 13.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.4ms\n",
      "Speed: 1.6ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.2ms\n",
      "Speed: 1.7ms preprocess, 15.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.0ms\n",
      "Speed: 1.8ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.0ms\n",
      "Speed: 2.2ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.9ms\n",
      "Speed: 2.4ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.8ms\n",
      "Speed: 1.6ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.0ms\n",
      "Speed: 1.7ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.7ms\n",
      "Speed: 1.6ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.1ms\n",
      "Speed: 3.0ms preprocess, 16.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 13.9ms\n",
      "Speed: 1.3ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Object Detection with bounding boxes now complete. Annotated video has been savet to: output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "#1) Split the video into frames\n",
    "video_path = \"Assignment_3_video_ActiveTrack\"\n",
    "frames_folder = \"extracted_frames\"\n",
    "total_frames = split_video_to_frames(video_path, frames_folder)\n",
    "\n",
    "#2) Load a YOLO model (YOLOv8s pretrained on COCO)\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "#3. Detect and annotate frames with bounding box + centroid for \"car\" objects\n",
    "processed_folder = \"processed_frames\"\n",
    "detect_and_annotate(frames_folder, processed_folder, model, total_frames)\n",
    "                    \n",
    "#4. Rebuild the annotated frames into a new video\n",
    "output_video = \"output_video.mp4\"\n",
    "rebuild_video_from_frames(processed_folder, output_video, total_frames, fps=30)\n",
    "print(f\"Object Detection with bounding boxes now complete. Annotated video has been savet to: {output_video}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Kalman Filters with filterpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from filterpy.common import Q_discrete_white_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_kalman_filter(dt=1.0, process_var=1.0, measurement_var=5.0):\n",
    "    \"\"\"\n",
    "    Initializes a 2D Kalman Filter tracking (x, y, vx, vy).\n",
    "    dt: time step between frames (assume 1 frame per 'unit time')\n",
    "    process_var: process (model) variance\n",
    "    measurement_var: measurement variance\n",
    "    \"\"\"\n",
    "    kf = KalmanFilter(dim_x=4, dim_z=2)\n",
    "    \n",
    "    # State vector: [x, y, vx, vy]\n",
    "    # We'll initialize this dynamically once we get the first measurement.\n",
    "    kf.x = np.array([0, 0, 0, 0], dtype=float)\n",
    "    \n",
    "    # State transition matrix (F)\n",
    "    # [x]   [1  0  dt  0]\n",
    "    # [y] = [0  1  0   dt]\n",
    "    # [vx]  [0  0  1   0 ]\n",
    "    # [vy]  [0  0  0   1 ]\n",
    "    kf.F = np.array([[1, 0, dt, 0],\n",
    "                     [0, 1, 0, dt],\n",
    "                     [0, 0, 1, 0 ],\n",
    "                     [0, 0, 0, 1 ]], dtype=float)\n",
    "    \n",
    "    # Measurement function (H)\n",
    "    # We measure (x, y) only, so we map [x, y, vx, vy] -> [x, y].\n",
    "    kf.H = np.array([[1, 0, 0, 0],\n",
    "                     [0, 1, 0, 0]], dtype=float)\n",
    "    \n",
    "    # Covariance matrix (P)\n",
    "    # Initialize with some large uncertainty for velocities.\n",
    "    kf.P = np.eye(4) * 500.\n",
    "    \n",
    "    # R: measurement noise covariance\n",
    "    # We assume measurement noise is the same for x and y\n",
    "    kf.R = np.eye(2) * measurement_var\n",
    "    \n",
    "    # Q: process noise covariance\n",
    "    # We'll generate some basic process noise for the velocity components\n",
    "    q = Q_discrete_white_noise(dim=2, dt=dt, var=process_var)\n",
    "    # Q_discrete_white_noise generates a 2x2 matrix for the subspace (vx, vy).\n",
    "    # We need to embed it in a 4x4 for the full state.\n",
    "    kf.Q = np.block([\n",
    "        [np.zeros((2,2)),           np.zeros((2,2))],\n",
    "        [np.zeros((2,2)),           q              ]\n",
    "    ])\n",
    "    \n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measurement_for_frame(bboxes, frame_idx):\n",
    "    \"\"\"\n",
    "    Returns the (x, y) measurement for the given frame_idx\n",
    "    or None if no measurement is available.\n",
    "    \"\"\"\n",
    "    for (f_idx, x, y) in bboxes:\n",
    "        if f_idx == frame_idx:\n",
    "            return (x, y)\n",
    "    return None\n",
    "\n",
    "def rebuild_video(folder_path, output_video, total_frames, fps=30):\n",
    "    \"\"\"\n",
    "    Rebuilds a video from frames in folder_path,\n",
    "    saving it to output_video.\n",
    "    \"\"\"\n",
    "    first_frame_path = os.path.join(folder_path, \"frame_000000.jpg\")\n",
    "    first_frame = cv2.imread(first_frame_path)\n",
    "    if first_frame is None:\n",
    "        raise RuntimeError(\"No frames found to build video.\")\n",
    "    \n",
    "    height, width, _ = first_frame.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "    for i in range(total_frames):\n",
    "        frame_path = os.path.join(folder_path, f\"frame_{i:06d}.jpg\")\n",
    "        frame = cv2.imread(frame_path)\n",
    "        if frame is None:\n",
    "            continue\n",
    "        out.write(frame)\n",
    "    \n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bounding_box_centers(csv_file=\"detections.csv\"):\n",
    "    \"\"\"\n",
    "    Loads bounding box centers from a CSV file.\n",
    "    It Expects columns: frame_idx, x_center, y_center.\n",
    "    \n",
    "    Returns:\n",
    "        A list of tuples (frame_idx, x_center, y_center).\n",
    "    \"\"\"\n",
    "    bounding_boxes = []\n",
    "\n",
    "    with open(csv_file, 'r', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip header row if exist\n",
    "        for row in reader:\n",
    "            frame_idx = int(row[0])\n",
    "            x_center = float(row[2]) #centroid x_coordinate\n",
    "            y_center = float(row[3])  #centroid y_coordinate\n",
    "            bounding_boxes.append((frame_idx, x_center, y_center))\n",
    "    return bounding_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # --- 1. Prepare input paths ---\n",
    "    # The folder with frames from the YOLO detection step\n",
    "    processed_folder = \"processed_frames\"  # or \"extracted_frames\"\n",
    "    # specify new folder to store frames with the Kalman-filtered track\n",
    "    kalman_folder = \"kalman_filtered_frames\"\n",
    "    os.makedirs(kalman_folder, exist_ok=True)\n",
    "    \n",
    "    # The bounding box data for each frame (x_center, y_center).  \n",
    "    # Ex. bounding_boxes = [(0, 100, 200), (1, 101, 202), ...]\n",
    "    bounding_boxes = load_bounding_box_centers(\"detections.csv\")\n",
    "    \n",
    "    # Get Number of frames\n",
    "    total_frames = len(os.listdir(processed_folder))\n",
    "    \n",
    "    # 2) Initialize Kalman Filter\n",
    "    kf = initialize_kalman_filter(dt=1.0, process_var=1.0, measurement_var=5.0)\n",
    "    initialized = False\n",
    "    \n",
    "    # We'll store the innovation norm to analyze filter performance\n",
    "    innovation_norms = []\n",
    "    \n",
    "    # --- 3. Tracking Loop ---\n",
    "    for i in range(total_frames):\n",
    "        # Attempt to read bounding box center for frame i\n",
    "        # If no detection is found for this frame, measurement = None\n",
    "        measurement = get_measurement_for_frame(bounding_boxes, i)  # returns (x, y) or None\n",
    "        \n",
    "        # Kalman Filter: PREDICT step\n",
    "        kf.predict()\n",
    "        \n",
    "        # If we do not have an initial measurement yet, we skip update\n",
    "        # and just wait until we get a real measurement to initialize properly\n",
    "        if not initialized and measurement is not None:\n",
    "            # Initialize the filter state [x, y, vx, vy]\n",
    "            kf.x[0] = measurement[0]\n",
    "            kf.x[1] = measurement[1]\n",
    "            kf.x[2] = 0.0\n",
    "            kf.x[3] = 0.0 \n",
    "            # velocities set to 0 or estimate if you prefer\n",
    "            initialized = True\n",
    "        \n",
    "        # Kalman Filter: UPDATE step (if we have a new measurement)\n",
    "        if measurement is not None and initialized:\n",
    "            z = np.array([measurement[0], measurement[1]], dtype=float)\n",
    "            \n",
    "            # Compute predicted measurement for innovation\n",
    "            z_pred = kf.H @ kf.x  # or kf.H.dot(kf.x)\n",
    "            innovation = z - z_pred  # y = z - Hx\n",
    "            # Store the norm of the 2D innovation\n",
    "            innovation_magnitude = np.linalg.norm(innovation)\n",
    "            innovation_norms.append(innovation_magnitude)\n",
    "            \n",
    "            # Now update the filter with the actual measurement\n",
    "            kf.update(z)\n",
    "        else:\n",
    "            # If there's no measurement, we only have the prediction\n",
    "            # or we're not yet initialized, so no update\n",
    "            innovation_norms.append(None)  # No innovation for this step\n",
    "        \n",
    "        # --- 4. Draw the filtered centroid on the frame ---\n",
    "        frame_path = os.path.join(processed_folder, f\"frame_{i:06d}.jpg\")\n",
    "        frame = cv2.imread(frame_path)\n",
    "        if frame is None:\n",
    "            continue\n",
    "        \n",
    "        # Get the filters current best estimate (x, y)\n",
    "        x_est, y_est, vx_est, vy_est = kf.x\n",
    "        if initialized:\n",
    "            # Draw a circle for the Kalman-estimated position\n",
    "            cv2.circle(frame, (int(x_est), int(y_est)), 6, (0, 0, 255), -1)  # red circle\n",
    "            cv2.putText(frame, \"KF\",\n",
    "                        (int(x_est) + 10, int(y_est)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        \n",
    "        # Optionally, also draw the raw YOLO measurement in a different color\n",
    "        if measurement is not None:\n",
    "            cv2.circle(frame, (int(measurement[0]), int(measurement[1])), 4, (255, 0, 0), -1)  # blue\n",
    "        \n",
    "        # Save the new frame with Kalman annotation\n",
    "        out_path = os.path.join(kalman_folder, f\"frame_{i:06d}.jpg\")\n",
    "        cv2.imwrite(out_path, frame)\n",
    "    \n",
    "    # 5) Rebuild the annotated video\n",
    "    output_video = \"kalman_output_video.mp4\"\n",
    "    rebuild_video(kalman_folder, output_video, total_frames, fps=30)\n",
    "    \n",
    "    print(\"Kalman filtering complete. Innovation norms:\", innovation_norms)\n",
    "    print(f\"Output video saved to: {output_video}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalman filtering complete. Innovation norms: [None, None, None, None, None, None, None, None, None, None, None, 0.0, 1.0, None, None, None, None, None, None, None, None, None, None, None, None, None, 5.073767866125884, None, 0.5614483804855502, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 6.908589665459108, 2.543529730024819, None, None, None, None, None, None, 5.808801483744184, 4.096273009382025, 2.7973894043281677, 2.9787631137337294, 2.277730526855013, 2.6891516640531337, 2.1661533193347795, 2.6431223544431695, 2.1828726869439805, 1.8052554109685062, None, None, None, None, None, None, None, None, None, None, None, 0.5089902345051298, 0.2764601530394146, 0.1272960391571221, 0.08443738284337128, 1.508967004486005, 0.6892382261746632, 0.8453214660690003, 1.681709304386929, 1.6654256194857813, 1.286975006321671, 2.078119614679071, 2.028694934401208, 1.9984739136657628, 1.9270511933645975, 1.54665039202966, 2.069125261129234, 1.460985894391161, 2.2978607979008445, 2.829372932868798, 2.159093303302356, 2.975708743421028, 2.0186821078926465, 2.641904160540869, None, None, None, None, None, None, None, None, None, None, 7.805517641943227, 6.887661497229457, 6.361112548588771, 6.800851531034678, None, None, None, None, 7.319519699832645, None, 7.273062747796342, 6.607946095688654, 6.977202035511607, 7.006285952077384, 6.389209928011978, 5.531399820187922, None, None, None, 5.523602150977191, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 11.644156021984855, 6.8776227020708465, 5.948395028142189, None, 5.1508565539342435, 4.503089726672975, None, None, 4.7366555044833385, 5.099186271634108, 4.178449205533025, 3.675267188341626, 3.3252991548796214, 3.849052754733299, 3.0997519449564694, 3.373747668747823, 2.9243788894091947, 3.269366128868226, 3.6989427298927855, 3.935408239076595, 4.895988724026463, 4.0067154007077415, 3.7292030867301174, 4.290118518056994, 3.986314196263815, 3.682604082542854, 3.9773971125807654, 4.093456126907749, 3.204346134422162, 2.1250703945414138, 3.3968809828975437, None, None, None, None, 5.554299112267101, 5.075125796675638, 5.033123399313929, 5.252513532687714, 6.141288438899531, None, 7.145025207174689, 6.116186744916772, 7.072872964243032, 5.990499790648892, 6.33179094864948, None, None, None, None, None, None, 9.819317870471911, 9.929335408568212, 10.302514207078207, 10.289268057982442, 12.444306432572198, 11.781849710548803, 11.668820091308934, 11.674292853590858, 11.61380182617462, 12.235446246044054, 10.836843149763798, 11.621965548774197, 11.951315458582046, 11.86244112108953, 13.200555274279377, None, 14.103593151691118, None, 14.716338182607187, 14.009626111625684, 14.290719959652764, 13.683056954161083, 13.972126072478623, 14.265280609261339, 15.015807056258934, 14.850919476817927, 14.200621916161795, 14.494718743185379, 14.782922501630466, 14.176162740323765, 14.470494973742767, 13.872920864526105, 14.180616833103745, 14.945229302798781, 15.21825081139765, 14.60359415070736, 14.505811104524103, 14.76064666329101, 14.662419403381179, 14.903415600641575, 14.791710811203933, 14.15143830826136, 14.463614027850866, 13.8822843453068, 14.194733922339186, 13.61691426273914, 14.407592032270925, 13.370880951752481, 14.614205633142076, 14.47751907915059, 14.329126640011149, 13.724810382952771, 14.050482657971482, 13.48046424862521, 13.807159397281557, 12.364001682832551, 12.293152086940127, 13.063685204342432, 12.508850896800634, 11.170800356659793, 11.454772726644128, 10.939936490945323, 11.816551921447363, 10.786989601119178, None, None, None, 3.6301866703044836, None, None, 8.275811890795024, 6.642540833385581, 6.760674761416546, 6.195974275963506, None, 5.1811135847295615, 4.608581386453219, 4.044545759688374, 3.395781143641908, 3.0247060186522012, None, 4.851895196451136, 2.998931464497047, None, None, None, None, None, None, None, None, None, None, None, 8.27436141582244, 5.99229736956983, 5.263354099898194, 8.296196282705907, 9.61266511979772, 10.025978664784123, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "Output video saved to: kalman_output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "#run main\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Count Vehicular Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/VisDrone2019-DET-train.zip to 'datasets/VisDrone/VisDrone2019-DET-train.zip'...\n",
      "Downloading https://ultralytics.com/assets/VisDrone2019-DET-val.zip to 'datasets/VisDrone/VisDrone2019-DET-val.zip'...\n",
      "Downloading https://ultralytics.com/assets/VisDrone2019-DET-test-dev.zip to 'datasets/VisDrone/VisDrone2019-DET-test-dev.zip'...\n",
      "Downloading https://ultralytics.com/assets/VisDrone2019-DET-test-challenge.zip to 'datasets/VisDrone/VisDrone2019-DET-test-challenge.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/VisDrone/VisDrone2019-DET-train: 6471it [01:02, 102.79it/s]\n",
      "Converting datasets/VisDrone/VisDrone2019-DET-val: 548it [00:07, 77.90it/s] \n",
      "Converting datasets/VisDrone/VisDrone2019-DET-test-dev: 1610it [00:15, 104.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from ultralytics.utils.downloads import download\n",
    "\n",
    "\n",
    "\n",
    "# Download VisDrone Dataset\n",
    "dir = Path(\"./datasets/VisDrone\")  # dataset root dir\n",
    "\n",
    "def visdrone2yolo(dir):\n",
    "    \"\"\"Convert VisDrone annotations to YOLO format, creating label files with normalized bounding box coordinates.\"\"\"\n",
    "    from PIL import Image\n",
    "    from tqdm import tqdm\n",
    "    def convert_box(size, box):\n",
    "        # Convert VisDrone box to YOLO xywh box\n",
    "        dw = 1.0 / size[0]\n",
    "        dh = 1.0 / size[1]\n",
    "        return (box[0] + box[2] / 2) * dw, (box[1] + box[3] / 2) * dh, box[2] * dw, box[3] * dh\n",
    "    (dir / \"labels\").mkdir(parents=True, exist_ok=True)  # make labels directory\n",
    "    pbar = tqdm((dir / \"annotations\").glob(\"*.txt\"), desc=f\"Converting {dir}\")\n",
    "    for f in pbar:\n",
    "        img_size = Image.open((dir / \"images\" / f.name).with_suffix(\".jpg\")).size\n",
    "        lines = []\n",
    "        with open(f, encoding=\"utf-8\") as file:  # read annotation.txt\n",
    "            for row in [x.split(\",\") for x in file.read().strip().splitlines()]:\n",
    "                if row[4] == \"0\":  # VisDrone 'ignored regions' class 0\n",
    "                    continue\n",
    "                cls = int(row[5]) - 1\n",
    "                box = convert_box(img_size, tuple(map(int, row[:4])))\n",
    "                lines.append(f\"{cls} {' '.join(f'{x:.6f}' for x in box)}\\n\")\n",
    "                with open(str(f).replace(f\"{os.sep}annotations{os.sep}\", f\"{os.sep}labels{os.sep}\"), \"w\", encoding=\"utf-8\") as fl:\n",
    "                    fl.writelines(lines)  # write label.txt\n",
    "\n",
    "urls = [\n",
    "    \"https://github.com/ultralytics/assets/releases/download/v0.0.0/VisDrone2019-DET-train.zip\",\n",
    "    \"https://github.com/ultralytics/assets/releases/download/v0.0.0/VisDrone2019-DET-val.zip\",\n",
    "    \"https://github.com/ultralytics/assets/releases/download/v0.0.0/VisDrone2019-DET-test-dev.zip\",\n",
    "    \"https://github.com/ultralytics/assets/releases/download/v0.0.0/VisDrone2019-DET-test-challenge.zip\",\n",
    "]\n",
    "download(urls, dir=dir, curl=True, threads=4)\n",
    "# Convert\n",
    "for d in \"VisDrone2019-DET-train\", \"VisDrone2019-DET-val\", \"VisDrone2019-DET-test-dev\":\n",
    "    visdrone2yolo(dir / d)  # convert VisDrone annotations to YOLO labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Centroid Tracker Class\n",
    "class CentroidTracker:\n",
    "    def __init__(self, maxDisappeared=50, maxDistance=50):\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = {}      # objectID -> current centroid (x, y)\n",
    "        self.disappeared = {}  # objectID -> consecutive frame count without detection\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "        self.maxDistance = maxDistance\n",
    "        self.tracks = {}       # objectID -> list of centroids (history)\n",
    "        self.counted = {}      # objectID -> boolean flag if already counted\n",
    "\n",
    "    def register(self, centroid):\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.tracks[self.nextObjectID] = [centroid]\n",
    "        self.counted[self.nextObjectID] = False\n",
    "        self.nextObjectID += 1\n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "        del self.tracks[objectID]\n",
    "        del self.counted[objectID]\n",
    "\n",
    "    def update(self, inputCentroids):\n",
    "        # If no new centroids, mark all existing objects as disappeared.\n",
    "        if len(inputCentroids) == 0:\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "            return self.objects\n",
    "\n",
    "        # If no objects are currently tracked, register all input centroids.\n",
    "        if len(self.objects) == 0:\n",
    "            for centroid in inputCentroids:\n",
    "                self.register(centroid)\n",
    "            return self.objects\n",
    "\n",
    "        # Compute distance between each existing object and new centroid.\n",
    "        objectIDs = list(self.objects.keys())\n",
    "        objectCentroids = list(self.objects.values())\n",
    "        D = np.linalg.norm(np.array(objectCentroids)[:, np.newaxis] - np.array(inputCentroids), axis=2)\n",
    "\n",
    "        # Find the smallest distances and match them.\n",
    "        rows = D.min(axis=1).argsort()\n",
    "        cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "        usedRows = set()\n",
    "        usedCols = set()\n",
    "\n",
    "        for (row, col) in zip(rows, cols):\n",
    "            if row in usedRows or col in usedCols:\n",
    "                continue\n",
    "            if D[row, col] > self.maxDistance:\n",
    "                continue\n",
    "            objectID = objectIDs[row]\n",
    "            self.objects[objectID] = inputCentroids[col]\n",
    "            self.tracks[objectID].append(inputCentroids[col])\n",
    "            self.disappeared[objectID] = 0\n",
    "            usedRows.add(row)\n",
    "            usedCols.add(col)\n",
    "\n",
    "        # Mark unmatched existing objects as disappeared.\n",
    "        unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "        for row in unusedRows:\n",
    "            objectID = objectIDs[row]\n",
    "            self.disappeared[objectID] += 1\n",
    "            if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                self.deregister(objectID)\n",
    "\n",
    "        # Register new objects for unmatched input centroids.\n",
    "        unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "        for col in unusedCols:\n",
    "            self.register(inputCentroids[col])\n",
    "\n",
    "        return self.objects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(\"../../runs/mlflow/647870279470109661/99b156ce37314ea9af73e146223fc2f3/artifacts/weights/best.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames extracted: 726\n",
      "\n",
      "0: 384x640 1 traffic light, 1 bottle, 36.6ms\n",
      "Speed: 1.1ms preprocess, 36.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.2ms\n",
      "Speed: 1.7ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 35.3ms\n",
      "Speed: 1.9ms preprocess, 35.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.8ms\n",
      "Speed: 1.4ms preprocess, 30.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.4ms\n",
      "Speed: 1.8ms preprocess, 29.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.2ms preprocess, 31.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.8ms\n",
      "Speed: 1.8ms preprocess, 28.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.6ms\n",
      "Speed: 1.4ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.5ms preprocess, 28.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 traffic lights, 30.2ms\n",
      "Speed: 1.5ms preprocess, 30.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.3ms\n",
      "Speed: 2.3ms preprocess, 29.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.3ms preprocess, 28.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.5ms\n",
      "Speed: 1.5ms preprocess, 29.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.5ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 skateboard, 28.7ms\n",
      "Speed: 2.5ms preprocess, 28.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.3ms preprocess, 29.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.7ms\n",
      "Speed: 1.6ms preprocess, 30.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.7ms\n",
      "Speed: 2.6ms preprocess, 29.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.4ms\n",
      "Speed: 1.8ms preprocess, 30.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.5ms\n",
      "Speed: 1.8ms preprocess, 35.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.0ms\n",
      "Speed: 1.6ms preprocess, 29.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.6ms\n",
      "Speed: 2.2ms preprocess, 30.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.4ms\n",
      "Speed: 1.2ms preprocess, 30.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.7ms preprocess, 29.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 29.0ms\n",
      "Speed: 1.6ms preprocess, 29.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.4ms preprocess, 29.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.5ms\n",
      "Speed: 1.2ms preprocess, 29.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 1.8ms preprocess, 29.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.6ms preprocess, 29.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 2.1ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.2ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.0ms\n",
      "Speed: 1.4ms preprocess, 29.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.3ms\n",
      "Speed: 1.8ms preprocess, 30.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.3ms preprocess, 30.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.7ms preprocess, 29.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.4ms\n",
      "Speed: 1.3ms preprocess, 30.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.8ms preprocess, 30.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 2.4ms preprocess, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.7ms preprocess, 30.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.9ms preprocess, 31.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.2ms\n",
      "Speed: 1.5ms preprocess, 33.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.6ms\n",
      "Speed: 1.3ms preprocess, 29.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.5ms preprocess, 30.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.2ms\n",
      "Speed: 1.7ms preprocess, 29.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 2.7ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.5ms\n",
      "Speed: 1.5ms preprocess, 30.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.8ms preprocess, 29.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.8ms preprocess, 30.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.5ms preprocess, 29.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 29.2ms\n",
      "Speed: 1.7ms preprocess, 29.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.4ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.7ms preprocess, 30.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.9ms\n",
      "Speed: 2.4ms preprocess, 29.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 2.2ms preprocess, 31.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.9ms\n",
      "Speed: 3.0ms preprocess, 28.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.8ms preprocess, 28.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.6ms preprocess, 29.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.7ms\n",
      "Speed: 1.6ms preprocess, 30.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.2ms\n",
      "Speed: 1.9ms preprocess, 30.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.2ms preprocess, 29.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.5ms preprocess, 30.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.3ms preprocess, 29.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.3ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.3ms preprocess, 30.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.9ms\n",
      "Speed: 1.6ms preprocess, 30.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.3ms\n",
      "Speed: 1.9ms preprocess, 30.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.3ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.0ms\n",
      "Speed: 1.8ms preprocess, 29.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 5.0ms preprocess, 31.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.6ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.9ms\n",
      "Speed: 2.4ms preprocess, 29.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.4ms preprocess, 28.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.7ms preprocess, 30.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 1.5ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.9ms\n",
      "Speed: 2.0ms preprocess, 29.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.4ms\n",
      "Speed: 2.7ms preprocess, 29.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.8ms\n",
      "Speed: 1.4ms preprocess, 30.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.5ms\n",
      "Speed: 1.2ms preprocess, 32.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 1 traffic light, 30.5ms\n",
      "Speed: 1.3ms preprocess, 30.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 traffic lights, 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.4ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 1 traffic light, 30.4ms\n",
      "Speed: 2.0ms preprocess, 30.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 1 traffic light, 29.5ms\n",
      "Speed: 1.9ms preprocess, 29.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.4ms preprocess, 31.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.3ms\n",
      "Speed: 1.5ms preprocess, 31.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.4ms\n",
      "Speed: 2.0ms preprocess, 30.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.3ms\n",
      "Speed: 1.2ms preprocess, 30.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 33.2ms\n",
      "Speed: 2.1ms preprocess, 33.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 1.4ms preprocess, 29.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 30.9ms\n",
      "Speed: 1.4ms preprocess, 30.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.6ms\n",
      "Speed: 1.4ms preprocess, 32.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.6ms\n",
      "Speed: 1.5ms preprocess, 31.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.9ms preprocess, 32.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 33.7ms\n",
      "Speed: 1.3ms preprocess, 33.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.3ms\n",
      "Speed: 1.9ms preprocess, 30.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.7ms\n",
      "Speed: 1.7ms preprocess, 30.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.2ms\n",
      "Speed: 1.7ms preprocess, 31.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 1 traffic light, 30.6ms\n",
      "Speed: 1.7ms preprocess, 30.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 29.9ms\n",
      "Speed: 1.1ms preprocess, 29.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 34.0ms\n",
      "Speed: 1.5ms preprocess, 34.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 32.4ms\n",
      "Speed: 1.7ms preprocess, 32.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 1.6ms preprocess, 32.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 2.0ms preprocess, 30.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.6ms\n",
      "Speed: 2.0ms preprocess, 32.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 32.2ms\n",
      "Speed: 2.0ms preprocess, 32.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.9ms\n",
      "Speed: 2.3ms preprocess, 30.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.3ms\n",
      "Speed: 1.3ms preprocess, 30.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.2ms\n",
      "Speed: 2.0ms preprocess, 32.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.5ms preprocess, 31.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.5ms preprocess, 30.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.8ms\n",
      "Speed: 2.0ms preprocess, 31.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.5ms\n",
      "Speed: 1.8ms preprocess, 31.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 29.5ms\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.7ms preprocess, 31.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.4ms\n",
      "Speed: 2.5ms preprocess, 32.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 30.6ms\n",
      "Speed: 1.6ms preprocess, 30.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 1 traffic light, 32.1ms\n",
      "Speed: 1.8ms preprocess, 32.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.3ms\n",
      "Speed: 2.0ms preprocess, 31.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.6ms\n",
      "Speed: 2.4ms preprocess, 31.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.3ms\n",
      "Speed: 1.6ms preprocess, 30.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.1ms\n",
      "Speed: 1.6ms preprocess, 31.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.4ms\n",
      "Speed: 1.4ms preprocess, 30.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 32.1ms\n",
      "Speed: 2.0ms preprocess, 32.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.4ms\n",
      "Speed: 1.4ms preprocess, 30.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 32.5ms\n",
      "Speed: 2.1ms preprocess, 32.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 1 bottle, 31.4ms\n",
      "Speed: 1.9ms preprocess, 31.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 33.1ms\n",
      "Speed: 2.0ms preprocess, 33.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 1 traffic light, 32.5ms\n",
      "Speed: 1.7ms preprocess, 32.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 32.0ms\n",
      "Speed: 1.7ms preprocess, 32.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.6ms preprocess, 30.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 bottles, 30.0ms\n",
      "Speed: 1.1ms preprocess, 30.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 1 bottle, 29.7ms\n",
      "Speed: 1.1ms preprocess, 29.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 1 bottle, 30.6ms\n",
      "Speed: 1.4ms preprocess, 30.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 29.8ms\n",
      "Speed: 1.3ms preprocess, 29.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 1 bottle, 29.9ms\n",
      "Speed: 1.5ms preprocess, 29.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.4ms\n",
      "Speed: 1.6ms preprocess, 31.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.6ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.3ms preprocess, 30.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.7ms\n",
      "Speed: 2.2ms preprocess, 31.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 32.6ms\n",
      "Speed: 1.5ms preprocess, 32.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.2ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.7ms\n",
      "Speed: 1.2ms preprocess, 31.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 2.6ms preprocess, 31.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.4ms\n",
      "Speed: 2.0ms preprocess, 32.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 32.8ms\n",
      "Speed: 2.0ms preprocess, 32.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 33.4ms\n",
      "Speed: 2.1ms preprocess, 33.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 bottles, 31.0ms\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 29.9ms\n",
      "Speed: 1.6ms preprocess, 29.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.4ms\n",
      "Speed: 1.6ms preprocess, 29.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.0ms\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.2ms\n",
      "Speed: 1.9ms preprocess, 32.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.5ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.4ms\n",
      "Speed: 1.6ms preprocess, 31.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 32.1ms\n",
      "Speed: 2.0ms preprocess, 32.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 32.7ms\n",
      "Speed: 1.5ms preprocess, 32.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.5ms preprocess, 31.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.8ms\n",
      "Speed: 1.9ms preprocess, 31.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.4ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.7ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.6ms\n",
      "Speed: 1.5ms preprocess, 29.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.4ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.2ms preprocess, 31.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.6ms\n",
      "Speed: 2.4ms preprocess, 30.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.2ms\n",
      "Speed: 2.8ms preprocess, 30.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.6ms preprocess, 30.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 2.4ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.1ms\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.3ms\n",
      "Speed: 1.9ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.4ms\n",
      "Speed: 1.3ms preprocess, 30.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.2ms\n",
      "Speed: 2.0ms preprocess, 30.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.8ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.8ms\n",
      "Speed: 1.9ms preprocess, 32.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.2ms\n",
      "Speed: 1.9ms preprocess, 32.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.2ms\n",
      "Speed: 2.8ms preprocess, 31.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.4ms\n",
      "Speed: 2.1ms preprocess, 30.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.7ms preprocess, 31.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 32.9ms\n",
      "Speed: 1.4ms preprocess, 32.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 traffic lights, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 traffic lights, 31.8ms\n",
      "Speed: 1.9ms preprocess, 31.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.9ms\n",
      "Speed: 1.6ms preprocess, 30.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.2ms\n",
      "Speed: 1.4ms preprocess, 30.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 traffic lights, 30.8ms\n",
      "Speed: 2.2ms preprocess, 30.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.4ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.0ms\n",
      "Speed: 1.4ms preprocess, 30.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.6ms\n",
      "Speed: 1.4ms preprocess, 30.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.7ms\n",
      "Speed: 1.4ms preprocess, 30.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.3ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.4ms preprocess, 31.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 1.7ms preprocess, 32.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.7ms preprocess, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.4ms preprocess, 31.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 2.1ms preprocess, 32.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.7ms\n",
      "Speed: 1.9ms preprocess, 30.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 2.1ms preprocess, 31.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.5ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 1 bottle, 34.3ms\n",
      "Speed: 1.4ms preprocess, 34.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 2.1ms preprocess, 30.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.9ms\n",
      "Speed: 1.5ms preprocess, 32.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.9ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 1.6ms preprocess, 32.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.6ms preprocess, 31.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.5ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.8ms preprocess, 32.1ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.8ms preprocess, 32.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 suitcase, 2 bottles, 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 2.2ms preprocess, 31.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.1ms\n",
      "Speed: 1.5ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.4ms\n",
      "Speed: 2.6ms preprocess, 31.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.7ms preprocess, 31.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 1 bottle, 31.0ms\n",
      "Speed: 1.4ms preprocess, 31.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.3ms preprocess, 31.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 2.1ms preprocess, 30.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.3ms preprocess, 31.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.4ms preprocess, 30.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.5ms\n",
      "Speed: 1.4ms preprocess, 32.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 2.2ms preprocess, 30.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.2ms preprocess, 31.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.4ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.9ms\n",
      "Speed: 2.0ms preprocess, 31.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.9ms preprocess, 30.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.3ms\n",
      "Speed: 2.0ms preprocess, 33.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.4ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.3ms\n",
      "Speed: 2.9ms preprocess, 31.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 32.2ms\n",
      "Speed: 1.5ms preprocess, 32.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.0ms\n",
      "Speed: 1.8ms preprocess, 31.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 2.5ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.5ms preprocess, 32.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 30.7ms\n",
      "Speed: 1.6ms preprocess, 30.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.0ms\n",
      "Speed: 1.5ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 1 traffic light, 30.7ms\n",
      "Speed: 1.9ms preprocess, 30.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 29.7ms\n",
      "Speed: 1.4ms preprocess, 29.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 truck, 31.2ms\n",
      "Speed: 1.8ms preprocess, 31.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 32.2ms\n",
      "Speed: 1.4ms preprocess, 32.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 31.6ms\n",
      "Speed: 1.8ms preprocess, 31.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.5ms preprocess, 31.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 32.7ms\n",
      "Speed: 2.1ms preprocess, 32.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.6ms preprocess, 30.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.2ms\n",
      "Speed: 1.1ms preprocess, 30.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.5ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.1ms\n",
      "Speed: 1.3ms preprocess, 31.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 32.6ms\n",
      "Speed: 1.9ms preprocess, 32.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 30.4ms\n",
      "Speed: 1.5ms preprocess, 30.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.2ms\n",
      "Speed: 1.5ms preprocess, 31.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 32.7ms\n",
      "Speed: 1.8ms preprocess, 32.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.6ms\n",
      "Speed: 1.3ms preprocess, 32.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.6ms\n",
      "Speed: 1.7ms preprocess, 31.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.5ms preprocess, 30.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.6ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.1ms\n",
      "Speed: 1.8ms preprocess, 33.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.5ms preprocess, 31.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 2.5ms preprocess, 31.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.6ms\n",
      "Speed: 1.6ms preprocess, 31.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.5ms preprocess, 31.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.2ms preprocess, 31.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.1ms\n",
      "Speed: 1.7ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.3ms\n",
      "Speed: 1.4ms preprocess, 30.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.5ms preprocess, 30.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.1ms\n",
      "Speed: 1.5ms preprocess, 33.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.4ms\n",
      "Speed: 1.6ms preprocess, 30.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.2ms\n",
      "Speed: 1.5ms preprocess, 31.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 2.1ms preprocess, 31.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.3ms\n",
      "Speed: 2.8ms preprocess, 33.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.6ms\n",
      "Speed: 1.5ms preprocess, 31.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.1ms preprocess, 31.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.7ms preprocess, 31.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.5ms preprocess, 30.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.7ms preprocess, 31.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.7ms preprocess, 31.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.3ms preprocess, 31.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.4ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.7ms\n",
      "Speed: 2.1ms preprocess, 29.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.6ms preprocess, 31.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.4ms preprocess, 30.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.7ms\n",
      "Speed: 1.9ms preprocess, 30.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.5ms preprocess, 31.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.7ms preprocess, 31.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.5ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.5ms\n",
      "Speed: 2.4ms preprocess, 32.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.7ms preprocess, 31.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.7ms\n",
      "Speed: 1.2ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.1ms\n",
      "Speed: 2.0ms preprocess, 31.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 30.3ms\n",
      "Speed: 2.2ms preprocess, 30.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.6ms\n",
      "Speed: 1.6ms preprocess, 31.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.6ms preprocess, 31.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.4ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.1ms\n",
      "Speed: 2.0ms preprocess, 32.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 32.5ms\n",
      "Speed: 1.6ms preprocess, 32.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.0ms\n",
      "Speed: 1.8ms preprocess, 31.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.4ms\n",
      "Speed: 1.5ms preprocess, 31.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 traffic light, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.4ms\n",
      "Speed: 1.2ms preprocess, 31.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.4ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.6ms\n",
      "Speed: 1.6ms preprocess, 31.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 30.1ms\n",
      "Speed: 1.4ms preprocess, 30.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 30.4ms\n",
      "Speed: 2.2ms preprocess, 30.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 traffic lights, 29.9ms\n",
      "Speed: 1.5ms preprocess, 29.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.0ms\n",
      "Speed: 1.3ms preprocess, 31.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trains, 1 truck, 31.8ms\n",
      "Speed: 1.5ms preprocess, 31.8ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 1 traffic light, 36.2ms\n",
      "Speed: 1.3ms preprocess, 36.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 29.7ms\n",
      "Speed: 1.3ms preprocess, 29.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.5ms\n",
      "Speed: 1.5ms preprocess, 30.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.3ms preprocess, 31.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 truck, 32.4ms\n",
      "Speed: 2.2ms preprocess, 32.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.3ms\n",
      "Speed: 2.2ms preprocess, 30.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.6ms preprocess, 30.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 traffic lights, 30.8ms\n",
      "Speed: 1.7ms preprocess, 30.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.3ms\n",
      "Speed: 1.2ms preprocess, 30.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.7ms\n",
      "Speed: 2.3ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.0ms\n",
      "Speed: 2.3ms preprocess, 31.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.0ms\n",
      "Speed: 1.9ms preprocess, 31.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.6ms\n",
      "Speed: 1.6ms preprocess, 32.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 2.1ms preprocess, 29.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.4ms preprocess, 31.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.3ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.4ms\n",
      "Speed: 1.9ms preprocess, 31.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.6ms preprocess, 31.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.1ms\n",
      "Speed: 1.7ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.3ms\n",
      "Speed: 4.1ms preprocess, 32.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 30.0ms\n",
      "Speed: 1.6ms preprocess, 30.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.9ms\n",
      "Speed: 1.5ms preprocess, 30.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 29.5ms\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.8ms\n",
      "Speed: 1.4ms preprocess, 30.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 traffic lights, 31.6ms\n",
      "Speed: 1.2ms preprocess, 31.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 2.3ms preprocess, 31.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.7ms preprocess, 31.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.2ms preprocess, 29.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 36.4ms\n",
      "Speed: 1.7ms preprocess, 36.4ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 traffic lights, 29.6ms\n",
      "Speed: 2.1ms preprocess, 29.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.4ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.7ms\n",
      "Speed: 1.4ms preprocess, 31.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.0ms\n",
      "Speed: 1.7ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 29.8ms\n",
      "Speed: 2.1ms preprocess, 29.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.1ms\n",
      "Speed: 1.5ms preprocess, 31.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 33.3ms\n",
      "Speed: 1.7ms preprocess, 33.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 32.5ms\n",
      "Speed: 1.8ms preprocess, 32.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 32.7ms\n",
      "Speed: 1.3ms preprocess, 32.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 traffic lights, 38.1ms\n",
      "Speed: 2.1ms preprocess, 38.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.9ms\n",
      "Speed: 2.8ms preprocess, 30.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 29.6ms\n",
      "Speed: 1.4ms preprocess, 29.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.9ms\n",
      "Speed: 1.4ms preprocess, 30.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.5ms\n",
      "Speed: 1.4ms preprocess, 30.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.9ms\n",
      "Speed: 1.3ms preprocess, 31.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 33.1ms\n",
      "Speed: 2.4ms preprocess, 33.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 1 bottle, 30.6ms\n",
      "Speed: 1.5ms preprocess, 30.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.0ms\n",
      "Speed: 1.7ms preprocess, 31.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 32.4ms\n",
      "Speed: 2.1ms preprocess, 32.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 1 clock, 30.9ms\n",
      "Speed: 1.3ms preprocess, 30.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 traffic lights, 32.4ms\n",
      "Speed: 2.1ms preprocess, 32.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 traffic lights, 30.4ms\n",
      "Speed: 1.6ms preprocess, 30.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 traffic lights, 30.2ms\n",
      "Speed: 1.6ms preprocess, 30.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.4ms preprocess, 31.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.9ms\n",
      "Speed: 1.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.7ms\n",
      "Speed: 1.3ms preprocess, 30.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.4ms preprocess, 32.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.2ms\n",
      "Speed: 1.5ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.6ms\n",
      "Speed: 2.8ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.3ms\n",
      "Speed: 2.0ms preprocess, 31.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.3ms preprocess, 31.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 2.6ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.9ms\n",
      "Speed: 1.5ms preprocess, 30.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.5ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.6ms\n",
      "Speed: 1.5ms preprocess, 31.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.4ms preprocess, 31.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.7ms\n",
      "Speed: 1.5ms preprocess, 31.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.8ms\n",
      "Speed: 1.5ms preprocess, 30.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 2.6ms preprocess, 31.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.4ms\n",
      "Speed: 1.3ms preprocess, 33.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.3ms\n",
      "Speed: 1.7ms preprocess, 31.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 32.0ms\n",
      "Speed: 2.6ms preprocess, 32.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.1ms preprocess, 30.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.9ms\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.6ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.8ms\n",
      "Speed: 1.8ms preprocess, 30.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 1.9ms preprocess, 29.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.2ms preprocess, 31.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.1ms\n",
      "Speed: 1.5ms preprocess, 31.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 traffic lights, 30.7ms\n",
      "Speed: 2.7ms preprocess, 30.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.8ms\n",
      "Speed: 1.2ms preprocess, 30.8ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 2.9ms preprocess, 31.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.3ms\n",
      "Speed: 1.6ms preprocess, 31.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 2.5ms preprocess, 31.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.4ms\n",
      "Speed: 1.5ms preprocess, 33.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.5ms\n",
      "Speed: 1.4ms preprocess, 30.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.6ms\n",
      "Speed: 2.8ms preprocess, 31.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 1.7ms preprocess, 29.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.4ms preprocess, 32.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.7ms\n",
      "Speed: 2.3ms preprocess, 32.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 1.5ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.5ms preprocess, 30.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.8ms\n",
      "Speed: 2.8ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.2ms preprocess, 32.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.8ms preprocess, 31.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.8ms\n",
      "Speed: 2.3ms preprocess, 31.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 2.1ms preprocess, 31.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.4ms\n",
      "Speed: 1.3ms preprocess, 33.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.4ms\n",
      "Speed: 1.8ms preprocess, 30.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.5ms\n",
      "Speed: 1.7ms preprocess, 33.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.9ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 2.0ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 1.6ms preprocess, 32.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.6ms\n",
      "Speed: 1.8ms preprocess, 31.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.9ms preprocess, 31.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 2.0ms preprocess, 30.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.2ms preprocess, 32.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.3ms\n",
      "Speed: 2.8ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.5ms preprocess, 31.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.2ms\n",
      "Speed: 2.5ms preprocess, 33.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.3ms preprocess, 31.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.7ms\n",
      "Speed: 2.5ms preprocess, 30.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.5ms preprocess, 31.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.5ms preprocess, 31.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.7ms preprocess, 30.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.4ms preprocess, 31.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.9ms preprocess, 31.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.3ms preprocess, 31.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.1ms\n",
      "Speed: 1.9ms preprocess, 34.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.9ms\n",
      "Speed: 2.1ms preprocess, 31.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.9ms preprocess, 31.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.5ms preprocess, 30.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.9ms\n",
      "Speed: 1.5ms preprocess, 33.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.9ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.3ms preprocess, 30.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.4ms\n",
      "Speed: 2.7ms preprocess, 31.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.8ms preprocess, 31.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.7ms\n",
      "Speed: 1.8ms preprocess, 32.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 1.7ms preprocess, 32.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.7ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.8ms preprocess, 31.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 2.5ms preprocess, 31.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 2.1ms preprocess, 31.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.6ms\n",
      "Speed: 1.7ms preprocess, 31.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 2.4ms preprocess, 30.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.5ms preprocess, 32.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.5ms preprocess, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.3ms preprocess, 30.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.4ms\n",
      "Speed: 1.9ms preprocess, 30.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 1.4ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.8ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.4ms\n",
      "Speed: 1.4ms preprocess, 31.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.6ms\n",
      "Speed: 1.7ms preprocess, 31.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.7ms preprocess, 31.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.9ms\n",
      "Speed: 1.6ms preprocess, 31.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.7ms preprocess, 31.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.1ms\n",
      "Speed: 2.2ms preprocess, 32.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 1.4ms preprocess, 32.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.5ms\n",
      "Speed: 1.7ms preprocess, 32.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.7ms preprocess, 30.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.6ms preprocess, 30.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.2ms\n",
      "Speed: 1.5ms preprocess, 30.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.8ms\n",
      "Speed: 1.2ms preprocess, 31.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.7ms\n",
      "Speed: 1.8ms preprocess, 31.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.5ms\n",
      "Speed: 1.3ms preprocess, 30.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.9ms\n",
      "Speed: 1.2ms preprocess, 30.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.4ms\n",
      "Speed: 1.6ms preprocess, 30.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 skateboard, 30.5ms\n",
      "Speed: 1.7ms preprocess, 30.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.4ms\n",
      "Speed: 1.6ms preprocess, 31.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.5ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 1.3ms preprocess, 29.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 32.4ms\n",
      "Speed: 1.2ms preprocess, 32.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.4ms\n",
      "Speed: 1.2ms preprocess, 30.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.7ms\n",
      "Speed: 1.4ms preprocess, 30.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.2ms preprocess, 30.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.2ms\n",
      "Speed: 1.5ms preprocess, 31.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.7ms\n",
      "Speed: 1.6ms preprocess, 30.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.8ms preprocess, 31.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.0ms\n",
      "Speed: 1.8ms preprocess, 31.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.6ms\n",
      "Speed: 2.7ms preprocess, 33.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.3ms\n",
      "Speed: 1.5ms preprocess, 32.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.5ms\n",
      "Speed: 1.4ms preprocess, 31.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 1 bottle, 30.6ms\n",
      "Speed: 1.5ms preprocess, 30.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.4ms\n",
      "Speed: 1.5ms preprocess, 30.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.2ms\n",
      "Speed: 1.7ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.4ms\n",
      "Speed: 1.4ms preprocess, 30.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.0ms\n",
      "Speed: 2.6ms preprocess, 31.0ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.1ms\n",
      "Speed: 1.6ms preprocess, 30.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.1ms\n",
      "Speed: 3.4ms preprocess, 30.1ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.3ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.8ms\n",
      "Speed: 1.6ms preprocess, 31.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.1ms\n",
      "Speed: 1.2ms preprocess, 31.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.9ms\n",
      "Speed: 1.5ms preprocess, 31.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 32.1ms\n",
      "Speed: 1.5ms preprocess, 32.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.1ms preprocess, 32.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 2.3ms preprocess, 31.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.8ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.7ms preprocess, 32.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.6ms\n",
      "Speed: 2.4ms preprocess, 31.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.3ms\n",
      "Speed: 1.6ms preprocess, 30.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.9ms\n",
      "Speed: 1.5ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.1ms\n",
      "Speed: 2.2ms preprocess, 30.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.3ms\n",
      "Speed: 2.6ms preprocess, 32.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.6ms preprocess, 31.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 34.1ms\n",
      "Speed: 1.6ms preprocess, 34.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.5ms\n",
      "Speed: 1.1ms preprocess, 30.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.3ms\n",
      "Speed: 1.4ms preprocess, 30.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.8ms preprocess, 31.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.5ms preprocess, 30.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.4ms preprocess, 32.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.6ms preprocess, 31.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 32.0ms\n",
      "Speed: 1.2ms preprocess, 32.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.4ms\n",
      "Speed: 2.6ms preprocess, 31.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 2.1ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.7ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.3ms\n",
      "Speed: 1.9ms preprocess, 31.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.3ms\n",
      "Speed: 1.2ms preprocess, 30.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.8ms\n",
      "Speed: 1.5ms preprocess, 32.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.7ms\n",
      "Speed: 1.4ms preprocess, 31.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.2ms\n",
      "Speed: 1.3ms preprocess, 30.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 1 clock, 31.0ms\n",
      "Speed: 1.2ms preprocess, 31.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 1 clock, 31.2ms\n",
      "Speed: 1.5ms preprocess, 31.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.4ms\n",
      "Speed: 1.7ms preprocess, 30.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.8ms\n",
      "Speed: 1.6ms preprocess, 30.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.0ms\n",
      "Speed: 1.4ms preprocess, 31.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.2ms preprocess, 30.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.2ms\n",
      "Speed: 1.5ms preprocess, 33.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.5ms preprocess, 30.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.5ms\n",
      "Speed: 1.4ms preprocess, 31.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.4ms preprocess, 30.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 1.5ms preprocess, 32.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 31.5ms\n",
      "Speed: 1.6ms preprocess, 31.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 30.0ms\n",
      "Speed: 1.6ms preprocess, 30.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.4ms preprocess, 31.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 2.7ms preprocess, 31.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 2.3ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.2ms\n",
      "Speed: 1.7ms preprocess, 32.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.2ms\n",
      "Speed: 2.4ms preprocess, 34.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 2.7ms preprocess, 30.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.8ms preprocess, 31.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.9ms\n",
      "Speed: 1.4ms preprocess, 31.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 30.9ms\n",
      "Speed: 2.6ms preprocess, 30.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.6ms\n",
      "Speed: 1.9ms preprocess, 31.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 32.4ms\n",
      "Speed: 1.2ms preprocess, 32.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 30.1ms\n",
      "Speed: 1.7ms preprocess, 30.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 30.5ms\n",
      "Speed: 1.5ms preprocess, 30.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.3ms\n",
      "Speed: 1.5ms preprocess, 32.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.5ms\n",
      "Speed: 1.8ms preprocess, 31.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.3ms preprocess, 31.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.5ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.8ms preprocess, 32.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.8ms\n",
      "Speed: 1.6ms preprocess, 31.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 trucks, 31.1ms\n",
      "Speed: 1.2ms preprocess, 31.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 30.4ms\n",
      "Speed: 1.3ms preprocess, 30.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 truck, 31.6ms\n",
      "Speed: 1.4ms preprocess, 31.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 1.3ms preprocess, 31.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 30.8ms\n",
      "Speed: 1.6ms preprocess, 30.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 truck, 31.0ms\n",
      "Speed: 2.6ms preprocess, 31.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 30.7ms\n",
      "Speed: 1.6ms preprocess, 30.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 31.5ms\n",
      "Speed: 1.7ms preprocess, 31.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 airplane, 1 truck, 30.6ms\n",
      "Speed: 1.8ms preprocess, 30.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 30.4ms\n",
      "Speed: 1.6ms preprocess, 30.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.8ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.6ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.8ms\n",
      "Speed: 2.6ms preprocess, 31.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.5ms\n",
      "Speed: 3.5ms preprocess, 33.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.7ms\n",
      "Speed: 3.6ms preprocess, 35.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.5ms preprocess, 29.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 32.6ms\n",
      "Speed: 1.7ms preprocess, 32.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.5ms\n",
      "Speed: 1.7ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.2ms\n",
      "Speed: 1.9ms preprocess, 30.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 32.2ms\n",
      "Speed: 1.8ms preprocess, 32.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.6ms\n",
      "Speed: 2.1ms preprocess, 31.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.2ms\n",
      "Speed: 2.4ms preprocess, 30.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.6ms\n",
      "Speed: 1.2ms preprocess, 31.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.9ms\n",
      "Speed: 2.0ms preprocess, 30.9ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 1 skateboard, 29.5ms\n",
      "Speed: 1.4ms preprocess, 29.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 skateboard, 31.2ms\n",
      "Speed: 1.7ms preprocess, 31.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.4ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.5ms preprocess, 31.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 31.5ms\n",
      "Speed: 1.5ms preprocess, 31.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 30.2ms\n",
      "Speed: 1.4ms preprocess, 30.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 1 skateboard, 31.0ms\n",
      "Speed: 1.6ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 1 skateboard, 31.7ms\n",
      "Speed: 1.7ms preprocess, 31.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.3ms\n",
      "Speed: 1.8ms preprocess, 31.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 skateboard, 31.0ms\n",
      "Speed: 1.6ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.2ms\n",
      "Speed: 1.8ms preprocess, 30.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.5ms\n",
      "Speed: 2.1ms preprocess, 31.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 32.5ms\n",
      "Speed: 1.5ms preprocess, 32.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.2ms\n",
      "Speed: 2.4ms preprocess, 31.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 30.9ms\n",
      "Speed: 1.3ms preprocess, 30.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 32.3ms\n",
      "Speed: 1.6ms preprocess, 32.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 31.6ms\n",
      "Speed: 1.4ms preprocess, 31.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 truck, 30.6ms\n",
      "Speed: 1.9ms preprocess, 30.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 31.1ms\n",
      "Speed: 1.5ms preprocess, 31.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 32.3ms\n",
      "Speed: 1.6ms preprocess, 32.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 31.4ms\n",
      "Speed: 1.4ms preprocess, 31.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 1 suitcase, 32.2ms\n",
      "Speed: 1.5ms preprocess, 32.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 2 skateboards, 31.6ms\n",
      "Speed: 1.5ms preprocess, 31.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 1 skateboard, 31.6ms\n",
      "Speed: 2.5ms preprocess, 31.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 1 skateboard, 32.3ms\n",
      "Speed: 1.6ms preprocess, 32.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.0ms\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 1 skateboard, 31.9ms\n",
      "Speed: 1.6ms preprocess, 31.9ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 2 skateboards, 41.2ms\n",
      "Speed: 1.4ms preprocess, 41.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 2 skateboards, 28.5ms\n",
      "Speed: 1.3ms preprocess, 28.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 1 skateboard, 33.8ms\n",
      "Speed: 1.9ms preprocess, 33.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 1 traffic light, 3 skateboards, 30.7ms\n",
      "Speed: 1.8ms preprocess, 30.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 1 skateboard, 32.6ms\n",
      "Speed: 2.0ms preprocess, 32.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 1 traffic light, 32.8ms\n",
      "Speed: 1.5ms preprocess, 32.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 1 traffic light, 31.8ms\n",
      "Speed: 1.6ms preprocess, 31.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 5 trucks, 30.2ms\n",
      "Speed: 1.4ms preprocess, 30.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 32.4ms\n",
      "Speed: 1.7ms preprocess, 32.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 trucks, 31.8ms\n",
      "Speed: 1.9ms preprocess, 31.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.2ms\n",
      "Speed: 1.4ms preprocess, 31.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 1 traffic light, 31.8ms\n",
      "Speed: 1.2ms preprocess, 31.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 1 traffic light, 31.5ms\n",
      "Speed: 1.5ms preprocess, 31.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 31.0ms\n",
      "Speed: 1.4ms preprocess, 31.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 30.7ms\n",
      "Speed: 1.1ms preprocess, 30.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 2 traffic lights, 32.2ms\n",
      "Speed: 2.3ms preprocess, 32.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 4 trucks, 1 traffic light, 31.5ms\n",
      "Speed: 1.5ms preprocess, 31.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 trucks, 1 traffic light, 32.9ms\n",
      "Speed: 2.1ms preprocess, 32.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 2 traffic lights, 30.5ms\n",
      "Speed: 1.2ms preprocess, 30.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 1 traffic light, 29.9ms\n",
      "Speed: 3.5ms preprocess, 29.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 1 traffic light, 30.8ms\n",
      "Speed: 1.4ms preprocess, 30.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 1 traffic light, 31.0ms\n",
      "Speed: 2.3ms preprocess, 31.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 1 traffic light, 31.4ms\n",
      "Speed: 1.3ms preprocess, 31.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 4 trucks, 29.5ms\n",
      "Speed: 2.4ms preprocess, 29.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 1 traffic light, 30.2ms\n",
      "Speed: 1.3ms preprocess, 30.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 30.7ms\n",
      "Speed: 3.2ms preprocess, 30.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 trucks, 1 traffic light, 30.5ms\n",
      "Speed: 1.9ms preprocess, 30.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 trucks, 29.2ms\n",
      "Speed: 1.7ms preprocess, 29.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 4 trucks, 30.9ms\n",
      "Speed: 2.0ms preprocess, 30.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 30.3ms\n",
      "Speed: 1.1ms preprocess, 30.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 30.7ms\n",
      "Speed: 1.4ms preprocess, 30.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 trucks, 31.0ms\n",
      "Speed: 1.2ms preprocess, 31.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 trucks, 1 traffic light, 31.1ms\n",
      "Speed: 1.4ms preprocess, 31.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 trucks, 31.3ms\n",
      "Speed: 1.7ms preprocess, 31.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 trucks, 30.0ms\n",
      "Speed: 1.5ms preprocess, 30.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 5 trucks, 1 traffic light, 31.4ms\n",
      "Speed: 1.3ms preprocess, 31.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 3 trucks, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 1 traffic light, 31.0ms\n",
      "Speed: 2.1ms preprocess, 31.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 1 traffic light, 29.8ms\n",
      "Speed: 1.7ms preprocess, 29.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 4 trucks, 31.5ms\n",
      "Speed: 1.7ms preprocess, 31.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 trucks, 1 traffic light, 31.9ms\n",
      "Speed: 3.1ms preprocess, 31.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 3 trucks, 1 traffic light, 30.0ms\n",
      "Speed: 1.5ms preprocess, 30.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 4 trucks, 32.0ms\n",
      "Speed: 1.6ms preprocess, 32.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 4 trucks, 29.7ms\n",
      "Speed: 1.2ms preprocess, 29.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 30.6ms\n",
      "Speed: 2.6ms preprocess, 30.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 30.7ms\n",
      "Speed: 2.0ms preprocess, 30.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 1 traffic light, 30.7ms\n",
      "Speed: 1.5ms preprocess, 30.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 1 traffic light, 30.1ms\n",
      "Speed: 2.3ms preprocess, 30.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 1 traffic light, 30.8ms\n",
      "Speed: 1.6ms preprocess, 30.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 1 truck, 31.8ms\n",
      "Speed: 1.6ms preprocess, 31.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 1 traffic light, 30.6ms\n",
      "Speed: 1.9ms preprocess, 30.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 30.4ms\n",
      "Speed: 1.7ms preprocess, 30.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 1 traffic light, 30.9ms\n",
      "Speed: 1.4ms preprocess, 30.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 1 traffic light, 30.8ms\n",
      "Speed: 1.8ms preprocess, 30.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 trucks, 1 traffic light, 30.2ms\n",
      "Speed: 1.8ms preprocess, 30.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 30.8ms\n",
      "Speed: 1.2ms preprocess, 30.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 trucks, 30.9ms\n",
      "Speed: 1.3ms preprocess, 30.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 trucks, 47.6ms\n",
      "Speed: 1.8ms preprocess, 47.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 30.1ms\n",
      "Speed: 1.6ms preprocess, 30.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 trucks, 31.1ms\n",
      "Speed: 1.7ms preprocess, 31.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 4 trucks, 30.7ms\n",
      "Speed: 1.5ms preprocess, 30.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 trucks, 31.2ms\n",
      "Speed: 1.7ms preprocess, 31.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 trucks, 1 traffic light, 34.2ms\n",
      "Speed: 1.4ms preprocess, 34.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 5 trucks, 30.1ms\n",
      "Speed: 1.7ms preprocess, 30.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 5 trucks, 30.9ms\n",
      "Speed: 1.4ms preprocess, 30.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 trucks, 31.1ms\n",
      "Speed: 1.2ms preprocess, 31.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 trucks, 33.0ms\n",
      "Speed: 1.7ms preprocess, 33.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 trucks, 30.6ms\n",
      "Speed: 1.7ms preprocess, 30.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 trucks, 32.0ms\n",
      "Speed: 2.1ms preprocess, 32.0ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 30.5ms\n",
      "Speed: 1.4ms preprocess, 30.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 trucks, 1 traffic light, 31.1ms\n",
      "Speed: 1.6ms preprocess, 31.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 30.7ms\n",
      "Speed: 2.0ms preprocess, 30.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 31.1ms\n",
      "Speed: 2.0ms preprocess, 31.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 1 truck, 31.8ms\n",
      "Speed: 1.7ms preprocess, 31.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.1ms\n",
      "Speed: 2.2ms preprocess, 31.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 30.4ms\n",
      "Speed: 2.5ms preprocess, 30.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.4ms preprocess, 30.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.9ms\n",
      "Speed: 2.1ms preprocess, 31.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.5ms\n",
      "Speed: 1.8ms preprocess, 33.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.4ms\n",
      "Speed: 1.4ms preprocess, 31.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 32.1ms\n",
      "Speed: 2.8ms preprocess, 32.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 30.7ms\n",
      "Speed: 2.0ms preprocess, 30.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.5ms\n",
      "Speed: 1.4ms preprocess, 32.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.7ms preprocess, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 31.0ms\n",
      "Speed: 1.9ms preprocess, 31.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 31.5ms\n",
      "Speed: 1.3ms preprocess, 31.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 truck, 31.4ms\n",
      "Speed: 2.0ms preprocess, 31.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 31.0ms\n",
      "Speed: 2.2ms preprocess, 31.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.7ms\n",
      "Speed: 1.6ms preprocess, 30.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.7ms preprocess, 31.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.0ms\n",
      "Speed: 2.4ms preprocess, 33.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 31.4ms\n",
      "Speed: 1.6ms preprocess, 31.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 30.4ms\n",
      "Speed: 1.5ms preprocess, 30.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 31.7ms\n",
      "Speed: 1.9ms preprocess, 31.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 31.3ms\n",
      "Speed: 1.5ms preprocess, 31.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 trucks, 30.4ms\n",
      "Speed: 2.4ms preprocess, 30.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 31.7ms\n",
      "Speed: 2.2ms preprocess, 31.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.4ms preprocess, 30.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 31.7ms\n",
      "Speed: 1.7ms preprocess, 31.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 31.0ms\n",
      "Speed: 1.2ms preprocess, 31.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.3ms preprocess, 30.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 1.9ms preprocess, 29.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.7ms\n",
      "Speed: 1.7ms preprocess, 32.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.8ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 30.5ms\n",
      "Speed: 1.4ms preprocess, 30.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.3ms\n",
      "Speed: 1.7ms preprocess, 32.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 31.3ms\n",
      "Speed: 2.6ms preprocess, 31.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.9ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.2ms\n",
      "Speed: 2.3ms preprocess, 32.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.9ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.9ms\n",
      "Speed: 1.9ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 traffic lights, 32.5ms\n",
      "Speed: 1.6ms preprocess, 32.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main Vehicle Counting Pipeline Using Ultralytics YOLO\n",
    "\n",
    "video_path = \"Assignment3_Task3_video.mp4\"           # Your input video file\n",
    "frames_folder = \"extracted_frames_car_count\"         # Folder where frames will be stored\n",
    "processed_folder = \"processed_frames_car_count\"      # Folder to save annotated frames\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "# 1. Split video into frames using the helper function.\n",
    "total_frames = split_video_to_frames(video_path, frames_folder)\n",
    "print(f\"Total frames extracted: {total_frames}\")\n",
    "\n",
    "# 2. Get frame dimensions from the first frame.\n",
    "first_frame_path = os.path.join(frames_folder, \"frame_000000.jpg\")\n",
    "first_frame = cv2.imread(first_frame_path)\n",
    "if first_frame is None:\n",
    "    raise RuntimeError(\"Could not load the first frame.\")\n",
    "height, width, _ = first_frame.shape\n",
    "\n",
    "# 3. Define the counting line (horizontal line across the frame).\n",
    "line_y = int(height * 0.5)\n",
    "\n",
    "# 4) Initialize the YOLO model (using Ultralytics YOLOv8) and vehicle label set.\n",
    "model = YOLO(\"../../runs/mlflow/647870279470109661/99b156ce37314ea9af73e146223fc2f3/artifacts/weights/best.pt\") \n",
    "vehicle_labels = {\"car\", \"truck\", \"bus\", \"motorcycle\", \"motorbike\"}\n",
    "\n",
    "# 5) Initialize the centroid tracker and counters.\n",
    "ct = CentroidTracker(maxDisappeared=30, maxDistance=50)\n",
    "count_up = 0      # Vehicles moving upward (bottom to top)\n",
    "count_down = 0    # Vehicles moving downward (top to bottom)\n",
    "\n",
    "# For time series data.\n",
    "time_series = []\n",
    "counts_up_series = []\n",
    "counts_down_series = []\n",
    "\n",
    "# Retrieve fps from the video (using cv2.VideoCapture temporarily).\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "cap.release()\n",
    "duration = total_frames / fps\n",
    "\n",
    "# 6) Process each extracted frame.\n",
    "for i in range(total_frames):\n",
    "    frame_path = os.path.join(frames_folder, f\"frame_{i:06d}.jpg\")\n",
    "    frame = cv2.imread(frame_path)\n",
    "    if frame is None:\n",
    "        continue\n",
    "\n",
    "    # Run YOLO detection on the frame.\n",
    "    results = model(frame, conf=0.35)\n",
    "    centroids = []\n",
    "    # Iterate over detections.\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            cls_idx = int(box.cls[0])\n",
    "            label = r.names[cls_idx]\n",
    "            if label in vehicle_labels:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                cx = (x1 + x2) // 2\n",
    "                cy = (y1 + y2) // 2\n",
    "                centroids.append((cx, cy))\n",
    "                # Draw detection bounding box and centroid.\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "\n",
    "    # Update the centroid tracker.\n",
    "    objects = ct.update(centroids)\n",
    "\n",
    "    # Check each tracked object for line crossing.\n",
    "    for objectID, centroid in objects.items():\n",
    "        track = ct.tracks.get(objectID, [])\n",
    "        if len(track) >= 2:\n",
    "            prev_y = track[-2][1]\n",
    "            curr_y = track[-1][1]\n",
    "            if not ct.counted[objectID]:\n",
    "                if prev_y < line_y and curr_y >= line_y:\n",
    "                    count_down += 1\n",
    "                    ct.counted[objectID] = True\n",
    "                elif prev_y > line_y and curr_y <= line_y:\n",
    "                    count_up += 1\n",
    "                    ct.counted[objectID] = True\n",
    "\n",
    "        # Optionally label tracked object.\n",
    "        cv2.putText(frame, f\"ID {objectID}\", (centroid[0]-10, centroid[1]-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2)\n",
    "        cv2.circle(frame, (centroid[0], centroid[1]), 4, (255,255,0), -1)\n",
    "\n",
    "    # Draw the counting line.\n",
    "    cv2.line(frame, (0, line_y), (width, line_y), (0, 0, 255), 2)\n",
    "\n",
    "    # Record counts for time series.\n",
    "    time_series.append(i / fps)\n",
    "    counts_up_series.append(count_up)\n",
    "    counts_down_series.append(count_down)\n",
    "\n",
    "    # Save the annotated frame.\n",
    "    cv2.imwrite(os.path.join(processed_folder, f\"frame_{i:06d}.jpg\"), frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Duration (s): 30.28025\n",
      "Vehicles moving up: 0 Normalized: 0.0\n",
      "Vehicles moving down: 0 Normalized: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 7) Normalize the counts by video duration\n",
    "normalized_count_up = count_up / duration\n",
    "normalized_count_down = count_down / duration\n",
    "\n",
    "print(\"Video Duration (s):\", duration)\n",
    "print(\"Vehicles moving up:\", count_up, \"Normalized:\", normalized_count_up)\n",
    "print(\"Vehicles moving down:\", count_down, \"Normalized:\", normalized_count_down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8) Plot the counts over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_series, counts_up_series, label=\"Vehicles Up\")\n",
    "plt.plot(time_series, counts_down_series, label=\"Vehicles Down\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Vehicle Count\")\n",
    "plt.title(\"Vehicle Counts Over Time\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Rye - assignment_3)",
   "language": "python",
   "name": "assignment_3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
